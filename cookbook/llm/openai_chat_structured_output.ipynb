{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LLM: OpenAI Chat Completion with Structured Output\n",
    "\n",
    "This notebook demonstrates how to use the `OpenAIChatClient` from `Floki` to generate structured output using `Pydantic` models.\n",
    "\n",
    "We will:\n",
    "\n",
    "* Initialize the OpenAIChatClient.\n",
    "* Define a Pydantic model to structure the response.\n",
    "* Use the `response_format` parameter to get structured output from the LLM."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Install Required Libraries\n",
    "\n",
    "Ensure floki and pydantic are installed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install floki-ai python-dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Environment Variables\n",
    "\n",
    "Load your API keys or other configuration values using `dotenv`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "load_dotenv()  # Load environment variables from a `.env` file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enable Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Floki Libraries\n",
    "\n",
    "Import the necessary classes and types from Floki."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from floki import OpenAIChatClient\n",
    "from floki.types import UserMessage"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize LLM Client\n",
    "\n",
    "Create an instance of the `OpenAIChatClient`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.llm.openai.client.base:Initializing OpenAI client...\n"
     ]
    }
   ],
   "source": [
    "llmClient = OpenAIChatClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Pydantic Model\n",
    "\n",
    "Define a Pydantic model to represent the structured response from the LLM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "\n",
    "class Dog(BaseModel):\n",
    "    name: str\n",
    "    breed: str\n",
    "    reason: str"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate Structured Output (JSON)\n",
    "\n",
    "Use the generate method of the `OpenAIChatClient` with the `response_format` parameter to enforce the structure of the response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.llm.utils.request:A response format has been passed. structured_mode=json.\n",
      "INFO:floki.llm.utils.structure:Structured response mode: json\n",
      "INFO:floki.llm.openai.chat:Invoking ChatCompletion API.\n",
      "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/chat/completions \"HTTP/1.1 200 OK\"\n",
      "INFO:floki.llm.openai.chat:Chat completion retrieved successfully.\n",
      "INFO:floki.llm.utils.response:Structured output was successfully validated.\n",
      "INFO:floki.llm.utils.response:Returning an instance of <class '__main__.Dog'>.\n"
     ]
    }
   ],
   "source": [
    "response = llmClient.generate(\n",
    "    messages=[UserMessage(\"One famous dog in history.\")],\n",
    "    response_format=Dog,\n",
    "    # structured_mode=\"json\" # By default it is set to json \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dog(name='Hachiko', breed='Akita', reason=\"Hachiko became famous for his exceptional loyalty to his owner, Hidesaburo Ueno. Every day, Hachiko would wait for Ueno's return at the Shibuya train station, even after his owner passed away in 1925. Hachiko continued this routine for over nine years, earning recognition and admiration in Japan and around the world. His story highlights the strong bond between dogs and their owners and has been immortalized in books, films, and even a bronze statue at Shibuya Station.\")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
