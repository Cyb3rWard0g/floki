{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Searching for Research Papers in arXiv\n",
    "\n",
    "This notebook demonstrates how to interact with the `arXiv` API using `Floki`, specifically through the `ArxivFetcher` class. We will explore:\n",
    "\n",
    "* How to search for papers using advanced query strings.\n",
    "* How to filter results by date (e.g., last 24 hours).\n",
    "* How to retrieve metadata for papers.\n",
    "* How to download the top 5 papers for further exploration.\n",
    "* How to extract and process text from the downloaded PDFs, with each page stored as a separate document."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Install Required Libraries\n",
    "!pip install floki-ai\n",
    "!pip install arxiv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize Logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Necessary Modules\n",
    "\n",
    "Import the required module and set up the `ArxivFetcher` to start searching for papers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/wardog/Documents/GitHub/floki/.venv/lib/python3.12/site-packages/pydantic/_internal/_generate_schema.py:777: UserWarning: Mixing V1 models and V2 models (or constructs, like `TypeAdapter`) is not supported. Please upgrade `Settings` to V2.\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "from floki.document import ArxivFetcher\n",
    "\n",
    "# Initialize the fetcher\n",
    "fetcher = ArxivFetcher()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Search by Query String\n",
    "\n",
    "In this example, we search for papers related to \"machine learning\". The results are returned as `Document` objects with `text` as the summary and `metadata` containing details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: machine learning\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=machine+learning&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 100 of 374510 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 5 results for query: machine learning\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: PERSE: Personalized 3D Generative Avatars from A Single Portrait\n",
      "Authors: Hyunsoo Cha, Inhee Lee, Hanbyul Joo\n",
      "Summary: We present PERSE, a method for building an animatable personalized generative\n",
      "avatar from a reference portrait. Our avatar model enables facial attribute\n",
      "editing in a continuous and disentangled latent space to control each facial\n",
      "attribute, while preserving the individual's identity. To achieve this, our\n",
      "method begins by synthesizing large-scale synthetic 2D video datasets, where\n",
      "each video contains consistent changes in the facial expression and viewpoint,\n",
      "combined with a variation in a specific facial attribute from the original\n",
      "input. We propose a novel pipeline to produce high-quality, photorealistic 2D\n",
      "videos with facial attribute editing. Leveraging this synthetic attribute\n",
      "dataset, we present a personalized avatar creation method based on the 3D\n",
      "Gaussian Splatting, learning a continuous and disentangled latent space for\n",
      "intuitive facial attribute manipulation. To enforce smooth transitions in this\n",
      "latent space, we introduce a latent space regularization technique by using\n",
      "interpolated 2D faces as supervision. Compared to previous approaches, we\n",
      "demonstrate that PERSE generates high-quality avatars with interpolated\n",
      "attributes while preserving identity of reference person.\n",
      "\n",
      "Title: Action-Agnostic Point-Level Supervision for Temporal Action Detection\n",
      "Authors: Shuhei M. Yoshida, Takashi Shibata, Makoto Terao, Takayuki Okatani, Masashi Sugiyama\n",
      "Summary: We propose action-agnostic point-level (AAPL) supervision for temporal action\n",
      "detection to achieve accurate action instance detection with a lightly\n",
      "annotated dataset. In the proposed scheme, a small portion of video frames is\n",
      "sampled in an unsupervised manner and presented to human annotators, who then\n",
      "label the frames with action categories. Unlike point-level supervision, which\n",
      "requires annotators to search for every action instance in an untrimmed video,\n",
      "frames to annotate are selected without human intervention in AAPL supervision.\n",
      "We also propose a detection model and learning method to effectively utilize\n",
      "the AAPL labels. Extensive experiments on the variety of datasets (THUMOS '14,\n",
      "FineAction, GTEA, BEOID, and ActivityNet 1.3) demonstrate that the proposed\n",
      "approach is competitive with or outperforms prior methods for video-level and\n",
      "point-level supervision in terms of the trade-off between the annotation cost\n",
      "and detection performance.\n",
      "\n",
      "Title: SoS Certificates for Sparse Singular Values and Their Applications: Robust Statistics, Subspace Distortion, and More\n",
      "Authors: Ilias Diakonikolas, Samuel B. Hopkins, Ankit Pensia, Stefan Tiegel\n",
      "Summary: We study $\\textit{sparse singular value certificates}$ for random rectangular\n",
      "matrices. If $M$ is an $n \\times d$ matrix with independent Gaussian entries,\n",
      "we give a new family of polynomial-time algorithms which can certify upper\n",
      "bounds on the maximum of $\\|M u\\|$, where $u$ is a unit vector with at most\n",
      "$\\eta n$ nonzero entries for a given $\\eta \\in (0,1)$. This basic algorithmic\n",
      "primitive lies at the heart of a wide range of problems across algorithmic\n",
      "statistics and theoretical computer science.\n",
      "  Our algorithms certify a bound which is asymptotically smaller than the naive\n",
      "one, given by the maximum singular value of $M$, for nearly the widest-possible\n",
      "range of $n,d,$ and $\\eta$. Efficiently certifying such a bound for a range of\n",
      "$n,d$ and $\\eta$ which is larger by any polynomial factor than what is achieved\n",
      "by our algorithm would violate lower bounds in the SQ and low-degree\n",
      "polynomials models. Our certification algorithm makes essential use of the\n",
      "Sum-of-Squares hierarchy. To prove the correctness of our algorithm, we develop\n",
      "a new combinatorial connection between the graph matrix approach to analyze\n",
      "random matrices with dependent entries, and the Efron-Stein decomposition of\n",
      "functions of independent random variables.\n",
      "  As applications of our certification algorithm, we obtain new efficient\n",
      "algorithms for a wide range of well-studied algorithmic tasks. In algorithmic\n",
      "robust statistics, we obtain new algorithms for robust mean and covariance\n",
      "estimation with tradeoffs between breakdown point and sample complexity, which\n",
      "are nearly matched by SQ and low-degree polynomial lower bounds (that we\n",
      "establish). We also obtain new polynomial-time guarantees for certification of\n",
      "$\\ell_1/\\ell_2$ distortion of random subspaces of $\\mathbb{R}^n$ (also with\n",
      "nearly matching lower bounds), sparse principal component analysis, and\n",
      "certification of the $2\\rightarrow p$ norm of a random matrix.\n",
      "\n",
      "Title: Distributed Mixture-of-Agents for Edge Inference with Large Language Models\n",
      "Authors: Purbesh Mitra, Priyanka Kaswan, Sennur Ulukus\n",
      "Summary: Mixture-of-Agents (MoA) has recently been proposed as a method to enhance\n",
      "performance of large language models (LLMs), enabling multiple individual LLMs\n",
      "to work together for collaborative inference. This collaborative approach\n",
      "results in improved responses to user prompts compared to relying on a single\n",
      "LLM. In this paper, we consider such an MoA architecture in a distributed\n",
      "setting, where LLMs operate on individual edge devices, each uniquely\n",
      "associated with a user and equipped with its own distributed computing power.\n",
      "These devices exchange information using decentralized gossip algorithms,\n",
      "allowing different device nodes to talk without the supervision of a\n",
      "centralized server. In the considered setup, different users have their own LLM\n",
      "models to address user prompts. Additionally, the devices gossip either their\n",
      "own user-specific prompts or augmented prompts to generate more refined answers\n",
      "to certain queries. User prompts are temporarily stored in the device queues\n",
      "when their corresponding LLMs are busy. Given the memory limitations of edge\n",
      "devices, it is crucial to ensure that the average queue sizes in the system\n",
      "remain bounded. In this paper, we address this by theoretically calculating the\n",
      "queuing stability conditions for the device queues under reasonable\n",
      "assumptions, which we validate experimentally as well. Further, we demonstrate\n",
      "through experiments, leveraging open-source LLMs for the implementation of\n",
      "distributed MoA, that certain MoA configurations produce higher-quality\n",
      "responses compared to others, as evaluated on AlpacaEval 2.0 benchmark. The\n",
      "implementation is available at:\n",
      "https://github.com/purbeshmitra/distributed_moa.\n",
      "\n",
      "Title: Sparse chaos in cortical circuits\n",
      "Authors: Rainer Engelken, Michael Monteforte, Fred Wolf\n",
      "Summary: Nerve impulses, the currency of information flow in the brain, are generated\n",
      "by an instability of the neuronal membrane potential dynamics. Neuronal\n",
      "circuits exhibit collective chaos that appears essential for learning, memory,\n",
      "sensory processing, and motor control. However, the factors controlling the\n",
      "nature and intensity of collective chaos in neuronal circuits are not well\n",
      "understood. Here we use computational ergodic theory to demonstrate that basic\n",
      "features of nerve impulse generation profoundly affect collective chaos in\n",
      "neuronal circuits. Numerically exact calculations of Lyapunov spectra,\n",
      "Kolmogorov-Sinai-entropy, and upper and lower bounds on attractor dimension\n",
      "show that changes in nerve impulse generation in individual neurons moderately\n",
      "impact information encoding rates but qualitatively transform phase space\n",
      "structure. Specifically, we find a drastic reduction in the number of unstable\n",
      "manifolds, Kolmogorov-Sinai entropy, and attractor dimension. Beyond a critical\n",
      "point, marked by the simultaneous breakdown of the diffusion approximation, a\n",
      "peak in the largest Lyapunov exponent, and a localization transition of the\n",
      "leading covariant Lyapunov vector, networks exhibit sparse chaos: prolonged\n",
      "periods of near stable dynamics interrupted by short bursts of intense chaos.\n",
      "Analysis of large, more realistically structured networks supports the\n",
      "generality of these findings. In cortical circuits, biophysical properties\n",
      "appear tuned to this regime of sparse chaos. Our results reveal a close link\n",
      "between fundamental aspects of single-neuron biophysics and the collective\n",
      "dynamics of cortical circuits, suggesting that nerve impulse generation\n",
      "mechanisms are adapted to enhance circuit controllability and information flow.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Search for papers related to \"machine learning\"\n",
    "results = fetcher.search(query=\"machine learning\", max_results=5)\n",
    "\n",
    "# Display the metadata and summaries of the retrieved documents\n",
    "for doc in results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {', '.join(doc.metadata['authors'])}\")\n",
    "    print(f\"Summary: {doc.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Advanced Query Strings\n",
    "\n",
    "Here we demonstrate using advanced query strings with logical operators like `AND`, `OR`, and `NOT`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for papers where \"agents\" and \"cybersecurity\" both appear:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: all:(agents AND cybersecurity)\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3A%28agents+AND+cybersecurity%29&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 93 of 93 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 10 results for query: all:(agents AND cybersecurity)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity\n",
      "Authors: Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, Xiapu Luo\n",
      "Summary: Evaluating Large Language Models (LLMs) is crucial for understanding their\n",
      "capabilities and limitations across various applications, including natural\n",
      "language processing and code generation. Existing benchmarks like MMLU, C-Eval,\n",
      "and HumanEval assess general LLM performance but lack focus on specific expert\n",
      "domains such as cybersecurity. Previous attempts to create cybersecurity\n",
      "datasets have faced limitations, including insufficient data volume and a\n",
      "reliance on multiple-choice questions (MCQs). To address these gaps, we propose\n",
      "SecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in\n",
      "the cybersecurity domain. SecBench includes questions in various formats (MCQs\n",
      "and short-answer questions (SAQs)), at different capability levels (Knowledge\n",
      "Retention and Logical Reasoning), in multiple languages (Chinese and English),\n",
      "and across various sub-domains. The dataset was constructed by collecting\n",
      "high-quality data from open sources and organizing a Cybersecurity Question\n",
      "Design Contest, resulting in 44,823 MCQs and 3,087 SAQs. Particularly, we used\n",
      "the powerful while cost-effective LLMs to (1). label the data and (2).\n",
      "constructing a grading agent for automatic evaluation of SAQs.Benchmarking\n",
      "results on 13 SOTA LLMs demonstrate the usability of SecBench, which is\n",
      "arguably the largest and most comprehensive benchmark dataset for LLMs in\n",
      "cybersecurity. More information about SecBench can be found at our website, and\n",
      "the dataset can be accessed via the artifact link.\n",
      "\n",
      "Title: BotSim: LLM-Powered Malicious Social Botnet Simulation\n",
      "Authors: Boyu Qiao, Kun Li, Wei Zhou, Shilong Li, Qianqian Lu, Songlin Hu\n",
      "Summary: Social media platforms like X(Twitter) and Reddit are vital to global\n",
      "communication. However, advancements in Large Language Model (LLM) technology\n",
      "give rise to social media bots with unprecedented intelligence. These bots\n",
      "adeptly simulate human profiles, conversations, and interactions, disseminating\n",
      "large amounts of false information and posing significant challenges to\n",
      "platform regulation. To better understand and counter these threats, we\n",
      "innovatively design BotSim, a malicious social botnet simulation powered by\n",
      "LLM. BotSim mimics the information dissemination patterns of real-world social\n",
      "networks, creating a virtual environment composed of intelligent agent bots and\n",
      "real human users. In the temporal simulation constructed by BotSim, these\n",
      "advanced agent bots autonomously engage in social interactions such as posting\n",
      "and commenting, effectively modeling scenarios of information flow and user\n",
      "interaction. Building on the BotSim framework, we construct a highly\n",
      "human-like, LLM-driven bot dataset called BotSim-24 and benchmark multiple bot\n",
      "detection strategies against it. The experimental results indicate that\n",
      "detection methods effective on traditional bot datasets perform worse on\n",
      "BotSim-24, highlighting the urgent need for new detection strategies to address\n",
      "the cybersecurity threats posed by these advanced bots.\n",
      "\n",
      "Title: algoTRIC: Symmetric and asymmetric encryption algorithms for Cryptography -- A comparative analysis in AI era\n",
      "Authors: Naresh Kshetri, Mir Mehedi Rahman, Md Masud Rana, Omar Faruq Osama, James Hutson\n",
      "Summary: The increasing integration of artificial intelligence (AI) within\n",
      "cybersecurity has necessitated stronger encryption methods to ensure data\n",
      "security. This paper presents a comparative analysis of symmetric (SE) and\n",
      "asymmetric encryption (AE) algorithms, focusing on their role in securing\n",
      "sensitive information in AI-driven environments. Through an in-depth study of\n",
      "various encryption algorithms such as AES, RSA, and others, this research\n",
      "evaluates the efficiency, complexity, and security of these algorithms within\n",
      "modern cybersecurity frameworks. Utilizing both qualitative and quantitative\n",
      "analysis, this research explores the historical evolution of encryption\n",
      "algorithms and their growing relevance in AI applications. The comparison of SE\n",
      "and AE algorithms focuses on key factors such as processing speed, scalability,\n",
      "and security resilience in the face of evolving threats. Special attention is\n",
      "given to how these algorithms are integrated into AI systems and how they\n",
      "manage the challenges posed by large-scale data processing in multi-agent\n",
      "environments. Our results highlight that while SE algorithms demonstrate\n",
      "high-speed performance and lower computational demands, AE algorithms provide\n",
      "superior security, particularly in scenarios requiring enhanced encryption for\n",
      "AI-based networks. The paper concludes by addressing the security concerns that\n",
      "encryption algorithms must tackle in the age of AI and outlines future research\n",
      "directions aimed at enhancing encryption techniques for cybersecurity.\n",
      "\n",
      "Title: The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap\n",
      "Authors: Yedi Zhang, Yufan Cai, Xinyue Zuo, Xiaokun Luan, Kailong Wang, Zhe Hou, Yifan Zhang, Zhiyuan Wei, Meng Sun, Jun Sun, Jing Sun, Jin Song Dong\n",
      "Summary: Large Language Models (LLMs) have emerged as a transformative AI paradigm,\n",
      "profoundly influencing daily life through their exceptional language\n",
      "understanding and contextual generation capabilities. Despite their remarkable\n",
      "performance, LLMs face a critical challenge: the propensity to produce\n",
      "unreliable outputs due to the inherent limitations of their learning-based\n",
      "nature. Formal methods (FMs), on the other hand, are a well-established\n",
      "computation paradigm that provides mathematically rigorous techniques for\n",
      "modeling, specifying, and verifying the correctness of systems. FMs have been\n",
      "extensively applied in mission-critical software engineering, embedded systems,\n",
      "and cybersecurity. However, the primary challenge impeding the deployment of\n",
      "FMs in real-world settings lies in their steep learning curves, the absence of\n",
      "user-friendly interfaces, and issues with efficiency and adaptability.\n",
      "  This position paper outlines a roadmap for advancing the next generation of\n",
      "trustworthy AI systems by leveraging the mutual enhancement of LLMs and FMs.\n",
      "First, we illustrate how FMs, including reasoning and certification techniques,\n",
      "can help LLMs generate more reliable and formally certified outputs.\n",
      "Subsequently, we highlight how the advanced learning capabilities and\n",
      "adaptability of LLMs can significantly enhance the usability, efficiency, and\n",
      "scalability of existing FM tools. Finally, we show that unifying these two\n",
      "computation paradigms -- integrating the flexibility and intelligence of LLMs\n",
      "with the rigorous reasoning abilities of FMs -- has transformative potential\n",
      "for the development of trustworthy AI software systems. We acknowledge that\n",
      "this integration has the potential to enhance both the trustworthiness and\n",
      "efficiency of software engineering practices while fostering the development of\n",
      "intelligent FM tools capable of addressing complex yet real-world challenges.\n",
      "\n",
      "Title: Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents\n",
      "Authors: Ankita Samaddar, Nicholas Potteiger, Xenofon Koutsoukos\n",
      "Summary: Autonomous agents for cyber applications take advantage of modern defense\n",
      "techniques by adopting intelligent agents with conventional and\n",
      "learning-enabled components. These intelligent agents are trained via\n",
      "reinforcement learning (RL) algorithms, and can learn, adapt to, reason about\n",
      "and deploy security rules to defend networked computer systems while\n",
      "maintaining critical operational workflows. However, the knowledge available\n",
      "during training about the state of the operational network and its environment\n",
      "may be limited. The agents should be trustworthy so that they can reliably\n",
      "detect situations they cannot handle, and hand them over to cyber experts. In\n",
      "this work, we develop an out-of-distribution (OOD) Monitoring algorithm that\n",
      "uses a Probabilistic Neural Network (PNN) to detect anomalous or OOD situations\n",
      "of RL-based agents with discrete states and discrete actions. To demonstrate\n",
      "the effectiveness of the proposed approach, we integrate the OOD monitoring\n",
      "algorithm with a neurosymbolic autonomous cyber agent that uses behavior trees\n",
      "with learning-enabled components. We evaluate the proposed approach in a\n",
      "simulated cyber environment under different adversarial strategies.\n",
      "Experimental results over a large number of episodes illustrate the overall\n",
      "efficiency of our proposed approach.\n",
      "\n",
      "Title: Hacking CTFs with Plain Agents\n",
      "Authors: Rustem Turtayev, Artem Petrov, Dmitrii Volkov, Denis Volk\n",
      "Summary: We saturate a high-school-level hacking benchmark with plain LLM agent\n",
      "design. Concretely, we obtain 95% performance on InterCode-CTF, a popular\n",
      "offensive security benchmark, using prompting, tool use, and multiple attempts.\n",
      "This beats prior work by Phuong et al. 2024 (29%) and Abramovich et al. 2024\n",
      "(72%).\n",
      "  Our results suggest that current LLMs have surpassed the high school level in\n",
      "offensive cybersecurity. Their hacking capabilities remain underelicited: our\n",
      "ReAct&Plan prompting strategy solves many challenges in 1-2 turns without\n",
      "complex engineering or advanced harnessing.\n",
      "\n",
      "Title: Explore Reinforced: Equilibrium Approximation with Reinforcement Learning\n",
      "Authors: Ryan Yu, Mateusz Nowak, Qintong Xie, Michelle Yilin Feng, Peter Chin\n",
      "Summary: Current approximate Coarse Correlated Equilibria (CCE) algorithms struggle\n",
      "with equilibrium approximation for games in large stochastic environments but\n",
      "are theoretically guaranteed to converge to a strong solution concept. In\n",
      "contrast, modern Reinforcement Learning (RL) algorithms provide faster training\n",
      "yet yield weaker solutions. We introduce Exp3-IXrl - a blend of RL and\n",
      "game-theoretic approach, separating the RL agent's action selection from the\n",
      "equilibrium computation while preserving the integrity of the learning process.\n",
      "We demonstrate that our algorithm expands the application of equilibrium\n",
      "approximation algorithms to new environments. Specifically, we show the\n",
      "improved performance in a complex and adversarial cybersecurity network\n",
      "environment - the Cyber Operations Research Gym - and in the classical\n",
      "multi-armed bandit settings.\n",
      "\n",
      "Title: HackSynth: LLM Agent and Evaluation Framework for Autonomous Penetration Testing\n",
      "Authors: Lajos Muzsai, David Imolai, András Lukács\n",
      "Summary: We introduce HackSynth, a novel Large Language Model (LLM)-based agent\n",
      "capable of autonomous penetration testing. HackSynth's dual-module architecture\n",
      "includes a Planner and a Summarizer, which enable it to generate commands and\n",
      "process feedback iteratively. To benchmark HackSynth, we propose two new\n",
      "Capture The Flag (CTF)-based benchmark sets utilizing the popular platforms\n",
      "PicoCTF and OverTheWire. These benchmarks include two hundred challenges across\n",
      "diverse domains and difficulties, providing a standardized framework for\n",
      "evaluating LLM-based penetration testing agents. Based on these benchmarks,\n",
      "extensive experiments are presented, analyzing the core parameters of\n",
      "HackSynth, including creativity (temperature and top-p) and token utilization.\n",
      "Multiple open source and proprietary LLMs were used to measure the agent's\n",
      "capabilities. The experiments show that the agent performed best with the\n",
      "GPT-4o model, better than what the GPT-4o's system card suggests. We also\n",
      "discuss the safety and predictability of HackSynth's actions. Our findings\n",
      "indicate the potential of LLM-based agents in advancing autonomous penetration\n",
      "testing and the importance of robust safeguards. HackSynth and the benchmarks\n",
      "are publicly available to foster research on autonomous cybersecurity\n",
      "solutions.\n",
      "\n",
      "Title: Towards Type Agnostic Cyber Defense Agents\n",
      "Authors: Erick Galinkin, Emmanouil Pountrourakis, Spiros Mancoridis\n",
      "Summary: With computing now ubiquitous across government, industry, and education,\n",
      "cybersecurity has become a critical component for every organization on the\n",
      "planet. Due to this ubiquity of computing, cyber threats have continued to grow\n",
      "year over year, leading to labor shortages and a skills gap in cybersecurity.\n",
      "As a result, many cybersecurity product vendors and security organizations have\n",
      "looked to artificial intelligence to shore up their defenses. This work\n",
      "considers how to characterize attackers and defenders in one approach to the\n",
      "automation of cyber defense -- the application of reinforcement learning.\n",
      "Specifically, we characterize the types of attackers and defenders in the sense\n",
      "of Bayesian games and, using reinforcement learning, derive empirical findings\n",
      "about how to best train agents that defend against multiple types of attackers.\n",
      "\n",
      "Title: Multi-Agent Collaboration in Incident Response with Large Language Models\n",
      "Authors: Zefang Liu\n",
      "Summary: Incident response (IR) is a critical aspect of cybersecurity, requiring rapid\n",
      "decision-making and coordinated efforts to address cyberattacks effectively.\n",
      "Leveraging large language models (LLMs) as intelligent agents offers a novel\n",
      "approach to enhancing collaboration and efficiency in IR scenarios. This paper\n",
      "explores the application of LLM-based multi-agent collaboration using the\n",
      "Backdoors & Breaches framework, a tabletop game designed for cybersecurity\n",
      "training. We simulate real-world IR dynamics through various team structures,\n",
      "including centralized, decentralized, and hybrid configurations. By analyzing\n",
      "agent interactions and performance across these setups, we provide insights\n",
      "into optimizing multi-agent collaboration for incident response. Our findings\n",
      "highlight the potential of LLMs to enhance decision-making, improve\n",
      "adaptability, and streamline IR processes, paving the way for more effective\n",
      "and coordinated responses to cyber threats.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = fetcher.search(query=\"all:(agents AND cybersecurity)\", max_results=10)\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {', '.join(doc.metadata['authors'])}\")\n",
    "    print(f\"Summary: {doc.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for papers where \"quantum\" appears but not \"computing\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: all:(quantum NOT computing)\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3A%28quantum+NOT+computing%29&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 100 of 355744 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 10 results for query: all:(quantum NOT computing)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Holographic observers for time-band algebras\n",
      "Authors: Kristan Jensen, Suvrat Raju, Antony J. Speranza\n",
      "Summary: We study the algebra of observables in a time band on the boundary of anti-de\n",
      "Sitter space in a theory of quantum gravity. Strictly speaking this algebra\n",
      "does not have a commutant because products of operators within the time band\n",
      "give rise to operators outside the time band. However, we show that in a state\n",
      "where the bulk contains a macroscopic observer, it is possible to define a\n",
      "coarse-grained version of this algebra with a non-trivial commutant, and a\n",
      "resolution limited by the observer's characteristics. This algebra acts on a\n",
      "little Hilbert space that describes excitations about the observer's state and\n",
      "time-translated versions of this state. Our construction requires a choice of\n",
      "dressing that determines how elements of the algebra transform under the\n",
      "Hamiltonian. At leading order in gravitational perturbation theory, and with a\n",
      "specific choice of dressing, our construction reduces to the modular\n",
      "crossed-product described previously in the literature. We also prove a theorem\n",
      "showing that this is the only crossed product of a type III$_1$ algebra\n",
      "resulting in an algebra with a trace. This trace can be used to define entropy\n",
      "differences between states in the little Hilbert space that are insensitive to\n",
      "the properties of the observer. We discuss some technical challenges in\n",
      "extending this construction to higher orders in perturbation theory. Lastly, we\n",
      "review the construction of interior operators in the eternal black hole and\n",
      "show that they can be written as elements of a crossed product algebra.\n",
      "\n",
      "Title: Enhanced Two-Way Teleportation of Entangled States with Six-Qubit Cluster State\n",
      "Authors: Vedhanayagi R, Soubhik De, Basherrudin Mahmud Ahmed A, Alok Sharan\n",
      "Summary: This work presents a two-way teleportation protocol for the transfer of an\n",
      "unknown two-qubit quantum state between two parties Alice and Bob, utilizing a\n",
      "six-qubit cluster state. This bidirectional exchange is achieved by performing\n",
      "Bell measurements on the qubit pairs of Alice and Bob, ensuring the successful\n",
      "teleportation of the quantum state for both parties. We demonstrate the\n",
      "proposed protocol by designing a teleportation circuit that incorporates the\n",
      "necessary quantum gates. The fidelity of the teleportation process is evaluated\n",
      "through simulations, confirming the accuracy and reliability of the proposed\n",
      "scheme. The protocol restores teleported states without requiring CNOT\n",
      "operations or auxiliary qubits, offering a significant advantage in resource\n",
      "efficiency(utilization). A comparative analysis of the intrinsic efficiency\n",
      "with previous approaches establishes that the proposed protocol brings forth an\n",
      "efficient approach for achieving two-way quantum teleportation.\n",
      "\n",
      "Title: Causality and Stability from Acoustic Geometry\n",
      "Authors: Ignacy Sawicki, Georg Trenkler, Alexander Vikman\n",
      "Summary: Scalar-tensor theories with derivative interactions form backgrounds which\n",
      "spontaneously break Lorentz invariance. We investigate the dynamics of free\n",
      "scalar perturbations on general anisotropic backgrounds. We demonstrate that\n",
      "the phonons move on null geodesics of an acoustic spacetime described by its\n",
      "own metric and own connection featuring nonmetricity with respect to the usual\n",
      "spacetime metric. We give distinct physical interpretations to the acoustic\n",
      "metric and its inverse. The first defines rays and their phase velocities. The\n",
      "latter defines momenta and the dispersion relation. We classify possible\n",
      "acoustic geometries and provide a physical interpretation for them.\n",
      "  We discuss the phonon properties that moving observers, inequivalent owing to\n",
      "the breaking of Lorentz invariance, would measure. Ghosts and true gradient\n",
      "instabilities are to be read off from invariant properties of the acoustic\n",
      "metric - its signature and determinant. However, the choice of the observer's\n",
      "frame can cause some confusion and paradoxes, including apparent instabilities.\n",
      "For instance, complex phonon energies can appear entirely due to the\n",
      "ill-posedness of the Cauchy problem in the frame chosen. On the other hand,\n",
      "unbounded negative phonon energies can appear, without ghosts or gradient\n",
      "instabilities, for observers moving supersonically, when phonon Cherenkov\n",
      "radiation can be emitted.\n",
      "  The action for phonons also gives an acoustically covariantly conserved\n",
      "energy-momentum tensor (EMT) which is, however, not conserved in the usual\n",
      "spacetime. Nonetheless, in the presence of an acoustic timelike Killing vector,\n",
      "the acoustic Hamiltonian functional is a conserved charge in both the acoustic\n",
      "and in the usual spacetimes, and even has the same value in both. Thus, the\n",
      "acoustic Hamiltonian can be used to bound the motion of phonons interacting\n",
      "with other species living in the usual spacetime.\n",
      "\n",
      "Title: Junction conditions for higher order gravity theories from a Gibbons-Hawking-York boundary term\n",
      "Authors: Marcos A. Ramirez, Cristián Martínez\n",
      "Summary: In this work we study the problem of generalizing the Gibbons-Hawking-York\n",
      "boundary terms for general quadratic theories of gravity and develop a new\n",
      "method to obtain them. From these terms we derive the junction conditions for a\n",
      "subset of this family of theories that includes Gauss-Bonnet (GB) gravity. We\n",
      "re-obtain the well-known results for GB theory, generalize them to other\n",
      "quadratic theories and compare the resulting junction conditions with the ones\n",
      "already derived in the literature using other methods.\n",
      "\n",
      "Title: Cavity-QED Simulation of a Maser beyond the Mean-Field Approximation\n",
      "Authors: Xinpeng Shu, Yining Jiang, Hao Wu, Mark Oxborrow\n",
      "Summary: We here introduce a method for simulating, quantum mechanically, the dynamics\n",
      "of a maser where the strength of the magnetic field of the microwave mode being\n",
      "amplified by stimulated emission varies over the volume of the maser's\n",
      "spatially extended gain medium. This is very often the case in real systems.\n",
      "Our method generalizes the well-known Tavis-Cummings (T-C) model of cavity\n",
      "quantum electrodynamics (QED) to encompass quantum emitters whose coupling\n",
      "strengths to the maser's amplified mode vary over a distribution that can be\n",
      "accurately determined using an electromagnetic-field solver applied to the\n",
      "maser cavity's geometry and composition. We then solve our generalized T-C\n",
      "model to second order in cumulant expansion using publicly available\n",
      "Python-based software. We apply our methodology to a specific, experimentally\n",
      "measured maser based on an optically pumped crystal of pentacene-doped\n",
      "para-terphenyl. We demonstrate that certain distinct quantum-mechanical\n",
      "features exhibited by this maser's dynamics, most notably the observation of\n",
      "Rabi-like flopping associated with the generation of spin-photon Dicke states,\n",
      "can be accurately reproduced using our numerically solved model. The equivalent\n",
      "simpler model, that invokes the mean-field approximation, fails to do so. By\n",
      "constructing then solving for artificial (perfectly Gaussian) distributions, we\n",
      "go on to explore how the performance of this type of maser is affected by the\n",
      "spread in spin-photon coupling strengths. Our methodology thereby enables the\n",
      "maser's anatomy to be more rationally engineered.\n",
      "\n",
      "Title: Quantum uncertainty in the area of a black hole\n",
      "Authors: Maulik Parikh, Jude Pereira\n",
      "Summary: Quantum fluctuations of the spacetime metric induce an uncertainty in the\n",
      "horizon area of a black hole. Working in linearized quantum gravity, we derive\n",
      "the variance in the area of a four-dimensional Schwarzschild black hole from\n",
      "the renormalized graviton propagator. We find that the standard deviation of\n",
      "the horizon area scales as the product of the Schwarzschild radius and the\n",
      "Planck length. For macroscopic black holes, the quantum uncertainty is\n",
      "therefore enormous in Planck units.\n",
      "\n",
      "Title: Accidental Peccei-Quinn Symmetry From Gauged U(1) and a High Quality Axion\n",
      "Authors: K. S. Babu, Bhaskar Dutta, Rabindra N. Mohapatra\n",
      "Summary: We construct explicit models that solve the axion quality problem originating\n",
      "from quantum gravitational effects. The general strategy we employ is to\n",
      "supplement the Standard Model and its grand unified extensions by an\n",
      "anomaly-free axial $U(1)_a$ symmetry that is gauged. We show that for several\n",
      "choices of the gauge quantum numbers of the fermions, this setup leads to an\n",
      "accidental $U(1)$ symmetry with a QCD anomaly which is identified as the\n",
      "Peccei-Quinn (PQ) symmetry that solves the strong CP problem. The $U(1)_a$\n",
      "gauge symmetry controls the amount of explicit PQ symmetry violation induced by\n",
      "quantum gravity, resulting in a high quality axion. We present two classes of\n",
      "models employing this strategy. In the first class (models I and II), the axial\n",
      "$U(1)_a$ gauge symmetry acts on vector-like quarks leading to an accidental\n",
      "KSVZ-type axion. The second class (model III) is based on $SO(10)$ grand\n",
      "unified theory extended by a gauged $U(1)_a$ symmetry that leads to a hybrid\n",
      "KSVZ--DFSZ type axion. The couplings of the axion to the electron and the\n",
      "nucleon are found to be distinct in this class of hybrid models from those in\n",
      "the KSVZ and DFSZ models, which can be used to test these models.\n",
      "Interestingly, all models presented here have domain wall number of one, which\n",
      "is free of cosmological problems that typically arise in axion models.\n",
      "\n",
      "Title: Particle-Soliton Degeneracy in 2D Quantum Chromodynamics\n",
      "Authors: Clay Cordova, Diego García-Sepúlveda, Nicholas Holfester\n",
      "Summary: Quantum chromodynamics in two spacetime dimensions admits a finite\n",
      "non-invertible symmetry described mathematically by a fusion category. This\n",
      "symmetry is spontaneously broken at long distances, leading to distinct vacua.\n",
      "When the theory has a mass gap, the spectrum is therefore characterized by\n",
      "particle excitations above a single vacuum and soliton sectors interpolating\n",
      "between vacua. We use anyon condensation and the representation theory of\n",
      "fusion categories to obtain exact results about this spectrum, exhibiting the\n",
      "allowed multiplets. Often, particles and solitons are in the same\n",
      "representation and therefore must have equal masses. Furthermore, the fusion\n",
      "category symmetry frequently implies the existence of certain stable states in\n",
      "the spectrum. The resulting degeneracies are encoded in quiver diagrams where\n",
      "nodes are vacua and arrows are excited states.\n",
      "\n",
      "Title: Topological dark energy from black-hole formations and mergers through the gravity-thermodynamics approach\n",
      "Authors: Stylianos A. Tsilioukas, Nicholas Petropoulos, Emmanuel N. Saridakis\n",
      "Summary: We apply the gravity-thermodynamics approach in the case of\n",
      "Einstein-Gauss-Bonnet theory, and its corresponding Wald-Gauss-Bonnet entropy,\n",
      "which due to the Chern-Gauss-Bonnet theorem it is related to the Euler\n",
      "characteristic of the Universe topology. However, we consider the realistic\n",
      "scenario where we have the formation and merger of black holes that lead to\n",
      "topology changes, which induce entropy changes in the Universe horizon. We\n",
      "extract the modified Friedmann equations and we obtain an effective dark energy\n",
      "sector of topological origin. We estimate the black-hole formation and merger\n",
      "rates starting from the observed star formation rate per redshift, which is\n",
      "parametrized very efficiently by the Madau-Dickinson form, and finally we\n",
      "result to a dark-energy energy density that depends on the cosmic star\n",
      "formation rate density, on the fraction $f_{\\text{BH}}$ of stars forming black\n",
      "holes, on the fraction of black holes $f_\\text{merge}$ that eventually merge,\n",
      "on the fraction $ f_{\\text{bin}}$ of massive stars that are in binaries, on the\n",
      "average mass of progenitor stars that will evolve to form black holes $ \\langle\n",
      "m_{\\text{prog}} \\rangle $, as well as on the Gauss-Bonnet coupling constant. We\n",
      "investigate in detail the cosmological evolution, obtaining the usual thermal\n",
      "history. Concerning the dark-energy equation-of-state parameter, we show that\n",
      "at intermediate redshifts it exhibits phantom-like or quintessence-like\n",
      "behavior according to the sign of the Gauss-Bonnet coupling, while at early and\n",
      "late times it tends to the cosmological constant value. Finally, we study the\n",
      "effect of the other model parameters, showing that for the whole allowed\n",
      "observationally estimated ranges, the topological dark-energy equation-of-state\n",
      "parameter remains within its observational bounds.\n",
      "\n",
      "Title: Gravitational EFT for dissipative open systems\n",
      "Authors: Pak Hang Chris Lau, Kanji Nishii, Toshifumi Noumi\n",
      "Summary: We elaborate on the effective field theory (EFT) construction for dissipative\n",
      "open systems coupled to dynamical gravity, in light of recent developments on\n",
      "the EFT of dissipative hydrodynamics (HydroEFT). Our construction is based on\n",
      "the Schwinger-Keldysh formalism and its symmetries as well as microscopic\n",
      "unitarity. A key aspect of dynamical gravity is that gravity couples to all\n",
      "degrees of freedom universally, hence the EFT has to take into account the\n",
      "energy-momentum tensor of the environment to which the energy escapes from the\n",
      "dissipative system of interest. We incorporate this effect by modeling the\n",
      "environment based on HydroEFT, assuming validity of the derivative expansion of\n",
      "the environment sector. For illustration, we apply our EFT recipe to a\n",
      "dissipative scalar field coupled to dynamical gravity that can be used, e.g.,\n",
      "for dissipative inflation. In particular we quantify impacts of fluctuations in\n",
      "the environment sector on the scalar dynamics. We also apply the same framework\n",
      "to dissipative gravity, discussing dissipative gravitational waves and the\n",
      "generalized second law of black hole thermodynamics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = fetcher.search(query=\"all:(quantum NOT computing)\", max_results=10)\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {', '.join(doc.metadata['authors'])}\")\n",
    "    print(f\"Summary: {doc.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Search for papers authored by a specific person"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: au:\"John Doe\"\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=au%3A%22John+Doe%22&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 1 of 1 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 1 results for query: au:\"John Doe\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Double Deep Q-Learning in Opponent Modeling\n",
      "Authors: Yangtianze Tao, John Doe\n",
      "Summary: Multi-agent systems in which secondary agents with conflicting agendas also\n",
      "alter their methods need opponent modeling. In this study, we simulate the main\n",
      "agent's and secondary agents' tactics using Double Deep Q-Networks (DDQN) with\n",
      "a prioritized experience replay mechanism. Then, under the opponent modeling\n",
      "setup, a Mixture-of-Experts architecture is used to identify various opponent\n",
      "strategy patterns. Finally, we analyze our models in two environments with\n",
      "several agents. The findings indicate that the Mixture-of-Experts model, which\n",
      "is based on opponent modeling, performs better than DDQN.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "results = fetcher.search(query='au:\"John Doe\"', max_results=10)\n",
    "\n",
    "for doc in results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {', '.join(doc.metadata['authors'])}\")\n",
    "    print(f\"Summary: {doc.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Filter Papers by Date (e.g., Last 24 Hours)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: all:(agents AND cybersecurity)\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3A%28agents+AND+cybersecurity%29+AND+submittedDate%3A%5B20241230+TO+20241231%5D&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 1 of 1 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 1 results for query: all:(agents AND cybersecurity) AND submittedDate:[20241230 TO 20241231]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity\n",
      "Authors: Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, Xiapu Luo\n",
      "Published: 2024-12-30\n",
      "Summary: Evaluating Large Language Models (LLMs) is crucial for understanding their\n",
      "capabilities and limitations across various applications, including natural\n",
      "language processing and code generation. Existing benchmarks like MMLU, C-Eval,\n",
      "and HumanEval assess general LLM performance but lack focus on specific expert\n",
      "domains such as cybersecurity. Previous attempts to create cybersecurity\n",
      "datasets have faced limitations, including insufficient data volume and a\n",
      "reliance on multiple-choice questions (MCQs). To address these gaps, we propose\n",
      "SecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in\n",
      "the cybersecurity domain. SecBench includes questions in various formats (MCQs\n",
      "and short-answer questions (SAQs)), at different capability levels (Knowledge\n",
      "Retention and Logical Reasoning), in multiple languages (Chinese and English),\n",
      "and across various sub-domains. The dataset was constructed by collecting\n",
      "high-quality data from open sources and organizing a Cybersecurity Question\n",
      "Design Contest, resulting in 44,823 MCQs and 3,087 SAQs. Particularly, we used\n",
      "the powerful while cost-effective LLMs to (1). label the data and (2).\n",
      "constructing a grading agent for automatic evaluation of SAQs.Benchmarking\n",
      "results on 13 SOTA LLMs demonstrate the usability of SecBench, which is\n",
      "arguably the largest and most comprehensive benchmark dataset for LLMs in\n",
      "cybersecurity. More information about SecBench can be found at our website, and\n",
      "the dataset can be accessed via the artifact link.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Calculate date 48 hours ago\n",
    "last_24_hours = (datetime.now() - timedelta(days=1)).strftime(\"%Y%m%d\")\n",
    "\n",
    "# Search for recent papers\n",
    "recent_results = fetcher.search(\n",
    "    query=\"all:(agents AND cybersecurity)\",\n",
    "    from_date=last_24_hours,\n",
    "    to_date=datetime.now().strftime(\"%Y%m%d\"),\n",
    "    max_results=5\n",
    ")\n",
    "\n",
    "# Display recent papers\n",
    "for doc in recent_results:\n",
    "    print(f\"Title: {doc.metadata['title']}\")\n",
    "    print(f\"Authors: {', '.join(doc.metadata['authors'])}\")\n",
    "    print(f\"Published: {doc.metadata['published']}\")\n",
    "    print(f\"Summary: {doc.text}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Top 5 Papers as PDF Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:floki.document.fetcher.arxiv:Searching for query: all:(agents AND cybersecurity)\n",
      "INFO:arxiv:Requesting page (first: True, try: 0): https://export.arxiv.org/api/query?search_query=all%3A%28agents+AND+cybersecurity%29&id_list=&sortBy=submittedDate&sortOrder=descending&start=0&max_results=100\n",
      "INFO:arxiv:Got first page: 93 of 93 total results\n",
      "INFO:floki.document.fetcher.arxiv:Found 5 results for query: all:(agents AND cybersecurity)\n",
      "INFO:floki.document.fetcher.arxiv:Downloading paper to arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf\n",
      "INFO:floki.document.fetcher.arxiv:Downloading paper to arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf\n",
      "INFO:floki.document.fetcher.arxiv:Downloading paper to arxiv_papers/2412.15237v1.algoTRIC__Symmetric_and_asymmetric_encryption_algorithms_for_Cryptography____A_comparative_analysis_in_AI_era.pdf\n",
      "INFO:floki.document.fetcher.arxiv:Downloading paper to arxiv_papers/2412.06512v1.The_Fusion_of_Large_Language_Models_and_Formal_Methods_for_Trustworthy_AI_Agents__A_Roadmap.pdf\n",
      "INFO:floki.document.fetcher.arxiv:Downloading paper to arxiv_papers/2412.02875v1.Out_of_Distribution_Detection_for_Neurosymbolic_Autonomous_Cyber_Agents.pdf\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded Paper: SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity\n",
      "File Path: arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf\n",
      "\n",
      "Downloaded Paper: BotSim: LLM-Powered Malicious Social Botnet Simulation\n",
      "File Path: arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf\n",
      "\n",
      "Downloaded Paper: algoTRIC: Symmetric and asymmetric encryption algorithms for Cryptography -- A comparative analysis in AI era\n",
      "File Path: arxiv_papers/2412.15237v1.algoTRIC__Symmetric_and_asymmetric_encryption_algorithms_for_Cryptography____A_comparative_analysis_in_AI_era.pdf\n",
      "\n",
      "Downloaded Paper: The Fusion of Large Language Models and Formal Methods for Trustworthy AI Agents: A Roadmap\n",
      "File Path: arxiv_papers/2412.06512v1.The_Fusion_of_Large_Language_Models_and_Formal_Methods_for_Trustworthy_AI_Agents__A_Roadmap.pdf\n",
      "\n",
      "Downloaded Paper: Out-of-Distribution Detection for Neurosymbolic Autonomous Cyber Agents\n",
      "File Path: arxiv_papers/2412.02875v1.Out_of_Distribution_Detection_for_Neurosymbolic_Autonomous_Cyber_Agents.pdf\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Create a directory for downloaded papers\n",
    "os.makedirs(\"arxiv_papers\", exist_ok=True)\n",
    "\n",
    "# Search and download PDFs\n",
    "download_results = fetcher.search(query=\"all:(agents AND cybersecurity)\", max_results=5, download=True, dirpath=Path(\"arxiv_papers\"))\n",
    "\n",
    "for paper in download_results:\n",
    "    print(f\"Downloaded Paper: {paper['title']}\")\n",
    "    print(f\"File Path: {paper['file_path']}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reading Downloaded PDFs\n",
    "\n",
    "To read the downloaded PDF files, we'll use the `PyPDFReader` class from floki.document. This allows us to extract the content of each page while retaining the associated metadata for further processing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure you have the required library for reading PDFs installed. If not, you can install it using the following command:\n",
    "!pip install pypdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following code reads each downloaded PDF file and extracts its pages. Each page is stored as a separate Document object, containing both the page's text and the metadata from the original PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:pypdf._reader:Ignoring wrong pointing object 6 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 8 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 10 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 12 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 14 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 16 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 18 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 20 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 40 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 45 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 54 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 78 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 87 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 89 0 (offset 0)\n",
      "WARNING:pypdf._reader:Ignoring wrong pointing object 91 0 (offset 0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracted 83 documents from the PDFs.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from floki.document import PyPDFReader\n",
    "\n",
    "# Initialize the PDF reader\n",
    "docs_read = []\n",
    "reader = PyPDFReader()\n",
    "\n",
    "# Process each downloaded PDF\n",
    "for paper in download_results:\n",
    "    local_pdf_path = Path(paper[\"file_path\"])  # Ensure the key matches the output\n",
    "    documents = reader.load(local_pdf_path, additional_metadata=paper)  # Load the PDF with metadata\n",
    "    \n",
    "    # Append each page's document to the main list\n",
    "    docs_read.extend(documents)  # Flatten into one list of all documents\n",
    "\n",
    "# Verify the results\n",
    "print(f\"Extracted {len(docs_read)} documents from the PDFs.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 1, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional\\nBenchmarking Dataset for LLMs in Cybersecurity\\nPENGFEI JING, The Hong Kong Polytechnic University, Tencent Security Keen Lab, China\\nMENGYUN TANG, Tencent Zhuque Lab, China\\nXIAORONG SHI, Tencent Zhuque Lab, China\\nXING ZHENG, Tencent Zhuque Lab, China\\nSEN NIE, Tencent Security Keen Lab, China\\nSHI WU, Tencent Security Keen Lab, China\\nYONG YANG,Tencent Security Platform and Department, China\\nXIAPU LUO, The Hong Kong Polytechnic University, China\\nEvaluating Large Language Models (LLMs) is crucial for understanding their capabilities and limitations across\\nvarious applications, including natural language processing and code generation. Existing benchmarks like\\nMMLU, C-Eval, and HumanEval assess general LLM performance but lack focus on specific expert domains\\nsuch as cybersecurity. Previous attempts to create cybersecurity datasets have faced limitations, including\\ninsufficient data volume and a reliance on multiple-choice questions (MCQs). To address these gaps, we\\npropose SecBench, a multi-dimensional benchmarking dataset designed to evaluate LLMs in the cybersecurity\\ndomain. SecBench includes questions in various formats (MCQs and short-answer questions (SAQs)), at\\ndifferent capability levels (Knowledge Retention and Logical Reasoning), in multiple languages (Chinese and\\nEnglish), and across various sub-domains. The dataset was constructed by collecting high-quality data from\\nopen sources and organizing a Cybersecurity Question Design Contest, resulting in 44,823 MCQs and 3,087\\nSAQs. Particularly, we used the powerful while cost-effective LLMs to (1). label the data and (2). constructing\\na grading agent for automatic evaluation of SAQs. Benchmarking results on 13 SOTA LLMs demonstrate the\\nusability of SecBench, which is arguably the largest and most comprehensive benchmark dataset for LLMs in\\ncybersecurity. More information about SecBench can be found at our website [13], and the dataset can be\\naccessed via the artifact link [12].\\n1 Introduction\\nEvaluating Large Language Models (LLMs) is essential for understanding their capabilities and\\nlimitations, as these models play a significant role in various applications, from natural language\\nprocessing to code generation. The importance of evaluating LLMs lies in ensuring their reliable\\nand effective performance across diverse tasks while identifying areas for improvement. Many\\nbenchmarks have been developed to assess different aspects of LLM performance, such as the\\nMMLU benchmark for general knowledge and reasoning [ 20], C-Eval for the Chinese context\\n[16], and HumanEval for code generation and completion [ 17]. These benchmarks collectively\\nprovide a comprehensive framework for evaluating the multifaceted capabilities of LLMs. However,\\nwhile these benchmarks focus on general capabilities, it is also crucial to evaluate LLMs in specific\\nexpert domains, such as cybersecurity. Previous studies have attempted to establish datasets for this\\npurpose [15, 18, 19, 21], but they face limitations, including insufficient evaluation data volume and\\na predominant use of multiple-choice questions (MCQs). A more challenging task, the short-answer\\nquestion (SAQ), which requires the model to generate its own answer, has not been explored in\\nthese studies.\\nAuthors’ Contact Information: Pengfei Jing, The Hong Kong Polytechnic University, Tencent Security Keen Lab, China;\\nMengyun Tang, Tencent Zhuque Lab, China; Xiaorong Shi, Tencent Zhuque Lab, China; Xing Zheng, Tencent Zhuque Lab,\\nChina; Sen Nie, Tencent Security Keen Lab, China; Shi Wu, Tencent Security Keen Lab, China; Yong Yang, Tencent Security\\nPlatform and Department, China; Xiapu Luo, The Hong Kong Polytechnic University, China.\\narXiv:2412.20787v1  [cs.CR]  30 Dec 2024'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 2, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='2 Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, and Xiapu Luo\\nTowards constructing a more comprehensive dataset and benchmarking large language models\\n(LLMs) in cybersecurity, we propose SecBench, a multi-dimensional benchmarking dataset designed\\nto evaluate LLMs in the cybersecurity domain. Specifically, SecBench assesses LLMs with questions\\nin various formats (multiple-choice questions (MCQs) and short-answer questions (SAQs)), at\\ndifferent capability levels (Knowledge Retention (KR) and Logical Reasoning (LR)), in multiple\\nlanguages (Chinese and English), and across various sub-domains, thereby covering a wide range\\nof knowledge in cybersecurity. To construct such an extensive dataset, we began by collecting\\nhigh-quality data from open sources, resulting in an initial dataset of 10,551 MCQs. To further\\nexpand this dataset both qualitatively and quantitatively, we organized a Cybersecurity Question\\nDesign Contest aimed at collecting high-quality questions from the public. After filtering and\\nprocessing the data collected from the contest, we obtained an additional 34,272 MCQs and 3,087\\nSAQs. Additionally, we utilized a powerful LLM, GPT-4, to automatically label the collected data\\naccording to their most relevant capability level and domain. Following the labeling process, we\\nderived SecBench, which consists of 44,823 MCQs and 3,087 SAQs, each well-labeled with detailed\\nmetadata.\\nTo achieve automatic evaluation of SAQs, we employed another powerful yet cost-efficient\\nLLM, GPT-4o-mini, as a grading agent to automatically grade the tested LLMs’ answers based on\\nthe question stem and ground truth (correct answer) provided by SecBench. For evaluation, we\\nconducted benchmarking of 13 State-of-the-Art LLMs on SecBench, demonstrating the usability of\\nSecBench both qualitatively and quantitatively.\\nThe remainder of this paper is structured as follows. §2 provides the necessary background\\ninformation. We introduce the design of SecBench in §3 and detail the dataset construction process\\nin §4. Then we present the benchmarking results in §5, discussion in §6, and conclude with §7.\\nMore information about SecBench can be found at our website [13], and the dataset can be accessed\\nvia the artifact link [12].\\n2 Background\\nBenchmarking LLMs.Evaluating Large Language Models (LLMs) is crucial for understanding\\ntheir capabilities and limitations, as these models have become increasingly influential in various\\napplications, from natural language processing to code generation and beyond. The significance\\nof evaluating LLMs lies in ensuring that they perform reliably and effectively in diverse tasks,\\nwhile also identifying areas for improvement. Several popular benchmarks have been developed\\nto assess different aspects of LLM performance. For instance, the MMLU benchmark evaluates\\ngeneral knowledge and reasoning across a wide range of subjects [20]. C-Eval [16] focuses on LLM’s\\ncapability in the specific Chinese context. HumanEval [17] is designed to assess code generation\\nand completion tasks. These benchmarks collectively provide a comprehensive framework for\\nevaluating the multifaceted capabilities of LLMs.\\nBenchmarking LLM in Cybersecurity.The benchmarks discussed earlier primarily focus on\\nassessing the general capabilities of LLMs. However, since LLMs are often fine-tuned for specific\\nexpert domains, it is crucial to evaluate their performance across various specialized fields. In the\\ncontext of cybersecurity, previous studies have attempted to establish datasets to assess LLMs’\\nknowledge in this particular domain [15, 18, 19, 21]. Unfortunately, these studies face two main\\nlimitations. First, the average volume of evaluation data is only at the thousand-level, which may\\nnot be sufficient to provide a comprehensive benchmark. Second, the question design in previous\\nworks predominantly follows the multiple-choice question (MCQ) format, which merely requires\\nthe model to select the correct answer from given options. However, a more challenging task, the\\nshort-answer question (SAQ), which requires the model to generate its own answer rather than\\nchoosing from existing ones, has not been explored in previous studies.'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 3, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity 3\\nMulti-Language SecBench\\nDataset\\nChinese\\n English\\nMulti-Level\\nKnowledge\\nRetention\\nLogical\\nReasoning\\nMulti-Form\\nMultiple Choice\\nQuestion - MCQ\\nShort Answer\\nQuestion - SAQ\\nMulti-\\nDomain\\nD1. Security\\nManagement\\nD3. Network and\\nInfrastructure Security\\nD2. Data\\nSecurity\\nD4. Security Standards\\nand Regulations\\nD5. Application\\nSecurity\\nD6. Identity and\\nAccess Control\\nD7. Fundamental Software and\\nHardware Technology\\nD8. Endpoint and\\nHost Security\\nD9. Cloud\\nSecurity\\nFig. 1. SecBench: A multi-level, multi-language, multi-form, and multi-domain benchmarking dataset for\\nLLM in Cybersecurity.\\n3 SecBench Design\\nFig.1 shows the overview of the SecBench design: it is a comprehensive benchmarking dataset\\naiming to benchmark LLM’s capability in cybersecurity from Multi-Level, Multi-Language, Multi-\\nForm, Multi-Domain.\\nMulti-Level. We devise the capability of LLM in cybersecurity into two different levels: Knowl-\\nedge Retention - KR and Logical Reasoning - LR . Among the two, knowledge retention examines the\\nLLM’s ability to retain existing knowledge. The content of such questions is relatively straightfor-\\nward and does not involve complex reasoning. On the other hand, logical reasoning assesses the\\nLLM’s ability to infer the correct answer based on the given information. The difficulty of these\\nquestions is relatively higher and better demonstrates the model’s capability to handle complex\\nproblems.\\nMulti-Language. SecBench includes questions of two mainstream languages - Chinese and\\nEnglish, to present a more comprehensive benchmark.\\nMulti-Form. Unlike previous works that constructed only multiple-choice questions (MCQs) [15,\\n18, 19, 21], SecBench also includes short-answer questions (SAQs) to present a more comprehensive\\nevaluation. This is because SAQs tend to be more challenging than MCQs: for MCQs, the LLM\\nonly needs to choose the correct answer(s) from the given options, while for SAQs, the LLM is\\nprompted to construct its own answer based on the given question. As a result, SAQs can evaluate\\nthe capability of the LLM at a higher level, especially considering the inherent limitations of LLMs\\n(e.g., hallucinations and repetition).\\nMulti-Domain. The questions in SecBench consist of 9 different domains, includingD1. Security\\nManagement, D2. Data Security , D3. Network and Infrastructure Security , D4. Security Standards and\\nRegulations , D5. Application Security , D6. Identity and Access Control , D7. Fundamental Software\\nand Hardware and Technology , D8. Endpoint and Host Security , D9. Cloud Security . Particularly,\\nthe above domains were devised from several rounds of brainstorming and revision, which were\\nexpected to cover most (if not all) related sub-domains in cybersecurity. Note that we do not expect\\nthese domains to be orthogonal, and it is possible that one question can be reasonably labeled into\\ndifferent domains. In our dataset, one question is assigned only one most-related domain label from\\nD1 to D9.\\nExample. For each line of data, it is either an MCQ or SAQ, provided with the question stem\\nand corresponding answer, labeled with language (Chinese or English), level (Knowledge Retention\\nor Logical Reasoning) and domain (from D1 to D9).\\nFollowing is one MCQ example, labeled in the domain of Security Management and the level of\\nLogical Reasoning . For MCQs, A blank is left in question stem, and there are four choices given in\\nanswers for the tested LLM to select, with label referring to the correct choice(s) among the four.'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 4, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='4 Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, and Xiapu Luo\\nRaw Materials\\ncleaning &\\nextraction\\nMCQ stems &\\nAnswers\\nLabeled\\nQuestions\\nLLM Labelling\\nInitial Dataset: 10,551 MCQs\\nBenchmarking\\nLLMs\\nCybersecurity\\nQuestion Design\\nContest Large-Scale\\nCollected Data\\nData Quality\\nEvaluation\\n...\\nHigh-Quality Data\\nCandidates\\nLLM-based Cleaning &\\nLabelling\\nLarge-Scale Dataset Construction\\nInitial Dataset Construction\\nContest Dataset: 34,272 MCQs; 3,087 SAQs\\nSecBench\\n44,823 MCQs\\n3,087 SAQs\\nFig. 2. SecBench: Dataset Construction.\\n{\"question\":\"In an information security risk management activity of a unit, the risk assessment report\\nsuggested that there were high-risk vulnerabilities in the FTP service of Server A. Subsequently, the unit chose\\nthe treatment measure of shutting down the FTP service in risk treatment, so may I ask to which type of\\nrisk treatment this measure belongs to ()\", \" answers\":[\"Risk reduction\", \"Risk avoidance\", \"Risk transfer\", \"Risk\\nacceptance\"], \"label\":\"B\", \"language\":\"English\", \"domain\":\"Security Management\", \"level\":\"Logical Reasoning\"}\\nFollowing is one SAQ example, labeled in the domain ofData Security and the level of Knowledge\\nRetention. For SAQs, there is no choice given for selection, and the tested LLM is expected to\\nconstruct the answer from scratch. in SAQ, answer refers to the correct answer of the question\\nstem, which will be used to evaluate LLM’s output.\\n{\"question\":\"How does email encryption contribute to regulatory compliance and data protection efforts,\\nand what are some common encryption methods used to secure email communications?\", \" answer\":\"Email\\nencryption helps organizations comply with data protection regulations such as GDPR, HIPAA, and CCPA\\nby safeguarding sensitive information transmitted via email and preventing unauthorized access or disclo-\\nsure. Common encryption methods include symmetric encryption, asymmetric encryption, and end-to-end\\nencryption, each offering varying levels of security and usability. \", \" language\":\"English\", \"domain\":\"Data\\nSecurity\", \"level\":\"Knowledge Retention\"}\\n4 Dataset Construction Process\\n4.1 Initial Dataset Construction\\nQuestion Stems and Answers Extraction.We aim to construct a small batch of datasets to\\nvalidate the rationality of the SecBench framework. To achieve this goal, we first collect raw\\nmaterials from various sources that can be used to extract high-quality question data, including\\nreal exam questions from various cybersecurity fields, authoritative books, and so on. Starting\\nfrom these raw materials, we perform automated extraction of questions and answer data from\\nthese resources (for example, using regular expressions). After this step, we have collected a total\\nof 10,551 high-quality MCQs, covering different domains.\\nLLM-based Labeling.However, the dataset obtained in the previous step only contains question\\nstems and answers, lacking the corresponding labels. Therefore, we used the powerful large\\nlanguage model - GPT4 [ 4], to further label this part of the data. With our carefully designed\\nprompts, we utilized a powerful large model (GPT-4) to label these data, including tagging the\\ndifficulty level of the questions (whether it is Knowledge Retention or Logical Reasoning) and\\ntagging the specific domain that the questions assess (as mentioned earlier, from D1 to D9). After'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 5, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity 5\\nLogic Reasoning:\\n9.2%\\nKnowledge\\nRetention: 90.8%\\n Chinese: 80.4%\\nEnglish: 19.6%\\nD7. Fundamental\\nSoftware and Hardware\\nTechnology: 2.1%\\nD4. Security Standards\\nand Regulations: 14.4%\\nD9. Cloud\\nSecurity: 4.8%\\nD6. Identity and\\nAccess Control: 5.5%\\nD8. Endpoint and\\nHost Security: 14.0%\\nD1. Security\\nManagement: 17.0%\\nD5. Application \\nSecurity: 15.9%\\nD2. Data Security:\\n11.5%\\nD3. Network and\\nInfrastructure\\nSecurity: 14.9%\\n(a). Distribution of evaluation\\nlevels: KR and LR\\n (b). Distribution of domains: D1 to D9.\\n (c). Distribution of language\\nFig. 3. The distribution of evaluation level, domain and language of the 44,823 MCQs.\\nthis step, we successfully labeled all collected questions. These questions became the prototype\\nfor SecBench, and we used this part of the labeled high-quality data to preliminarily validate the\\nrationality of the SecBench design.\\n4.2 Large-Scale Dataset Construction\\nCybersecurity Question Design Contest.To further expand the SecBench dataset, we have\\norganized a large-scale Cybersecurity Question Design Contest [13]. In this contest, we expected\\nparticipants to submit high-quality evaluation data across multiple domains, which we would\\nsubsequently clean and incorporate into the SecBench database. Specifically, we categorized the\\ndata submitted in question into three quality levels, with different weight scores assigned to each\\nlevel to encourage participants to submit high-quality data:\\n- Qualified Quality: The question meets the submission format, contains no factual errors,\\nand is not duplicated with other questions submitted by the same or other participants.\\n- Medium Quality: The question has clear logic and expression, a well-defined domain, an\\nunambiguous answer, and provides a clear and reasonable explanation along with a verifiable\\nsource.\\n- High Quality: The question design should have breadth, depth, and challenge, thus providing\\na high degree of differentiation for the capabilities of different models.\\nLarge-Scale Data Cleaning and Labeling.With the huge amount of data collected from the\\ncontest, we first manually assign the quality level (qualified, medium or high, as stated above) to\\neach submission. This process is performed by experienced experts with enough years of work\\nexperience in the cybersecurity domain, ensuring the justification of the quality attribution process.\\nThen, a rule-based filtering of these high-quality questions was performed to rule out possible\\nduplications or incomplete data that were missed by the former human-based quality attribution.\\nFinally, similar to Sec.4.1, we labeled the questions by their level (KR or LR), language and domain\\nwith the help of LLM. After the whole process, we obtained a total of 34,277 MCQs and 3,087 SAQs,\\ngreatly expanding our initial dataset quantitatively (more MCQs) and qualitatively (introducing\\nthe new evaluation form - SAQs).\\n4.3 Dataset Distribution\\nMCQ. Fig.3 shows the data distribution of the 44,823 MCQs in SecBench. According to Fig.3(a), the\\nmajority of the MCQs fall into the KR category (90.8%), which is reasonable because MCQs tend to\\nhave short question stems and focus on testing the knowledge base of the LLM. Notably, 9.2% of\\nthe MCQs are of the LR type, requiring the LLM to perform reasoning to obtain the correct answer.\\nAs shown in Fig.3(b), the data distribution across the 9 domains is generally even, with D6, D7, and'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 6, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='6 Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, and Xiapu Luo\\nLogic Reasoning:\\n63.4%\\nKnowledge\\nRetention: 36.6%\\nChinese: 97.4%\\nEnglish: 2.6%\\nD7. Fundamental Software\\nand Hardware Technology: 1.0%\\nD4. Security Standards\\nand Regulations: 4.7%\\nD9. Cloud\\nSecurity: 3.6%\\nD6. Identity and\\nAccess Control: 4.4%\\nD8. Endpoint and\\nHost Security: 5.6%\\nD1. Security\\nManagement: 19.0%\\nD5. Application \\nSecurity: 29.5%\\nD2. Data Security:\\n12.7%\\nD3. Network and\\nInfrastructure\\nSecurity: 19.5%\\n(a). Distribution of evaluation\\nlevels: KR and LR\\n (b). Distribution of domains: D1 to D9.\\n (c). Distribution of language\\nFig. 4. The distribution of evaluation level, domain and language of the 3,087 SAQs.\\nD9 having relatively less data (5.5%, 2.1%, and 4.8%, respectively). It is important to note that, given\\nthe large size of the dataset (44,823 MCQs), even a 4.8% share corresponds to over 2,000 MCQs.\\nAccording to Fig.3(c), the majority (80.4%) of the MCQs are in Chinese, reflecting the context of\\nthe cybersecurity question design contest. Additionally, the 19.6% of English MCQs (nearly 9,000\\nquestions) provide a sufficient dataset for evaluating the LLM’s cybersecurity capabilities in an\\nEnglish context.\\nSAQ. Fig.4 shows the distribution of the evaluation level, domain, and language of the 3,087\\nSAQs. As indicated in Fig.4(a), 36.6% of the SAQs are designed to assess knowledge retention, while\\n63.4% are aimed at evaluating logic reasoning, indicating that the majority of SAQs are challenging\\nand require the LLM to perform reasoning. According to Fig.4(b), the domains D1, D2, D3, and D5\\nconstitute the majority of the assessed domains. Notably, even D7, which comprises only 1.0% of\\nthe SAQs, includes 32 high-quality questions, given the overall dataset size of 3,087. As shown in\\nFig.4(c), 97.4% of the SAQs are in Chinese, reflecting the context in which the contest was held,\\nresulting in questions primarily constructed in Chinese.\\n4.4 Benchmarking Process\\nMCQ. The evaluation of MCQ is rather intuitive: for each MCQ, we check whether the model’s\\noutput (i.e., model’s choice(s) among A, B, C, and D) is the same as the correct answer. For MCQs\\nthat involve more than one correct answer, model’s output is judged as correct only when it is\\nidentical to the correct answer, meaning that no points are awarded for incorrect or incomplete\\nselections. Particularly, the evaluation of MCQ is implemented on the widely-used open-sourced\\nevaluation framework - OpenCompass [10].\\nSAQ.Grading an SAQ is not as intuitive as grading MCQ, in which case we only need to determine\\nwhether the LLM’s choice is the correct one(s). Particularly, grading SAQs requires to understand\\nboth the question stem and the model prediction (answer), and then fairly grade this prediction\\nbased on the ground truth, which is expected to huge amount of manual effort. In our work, we\\nintroduce a Grading Agent to realize the automatic grading of SAQs, and Fig.5 shows the process\\nof how the SAQs were evaluation on tested LLMs. Specifically, each SAQ includes the question\\nstem and the ground truth (i.e., correct answer) of the question. The question stem is first fed\\ninto the tested LLMs to generate the Model Prediction , which is the LLMs’ answer waiting to be\\ngraded. Then, the three parts of data, including the question stem, ground truth, and the model\\nprediction will be given to the Grading Agent, which is a sufficiently powerful LLM to grade the\\nModel Prediction based on the ground truth, and output the corresponding scores. Specifically, this\\nGrading Agent should 1). be capable of fairly grading the model prediction, and 2). generate stable\\noutput (e.g., a final grading score for further processing) In our work, we choose the GPT-4o mini'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 7, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity 7\\nSecBench\\nSAQs\\nQuestion\\nStem\\nGround\\nTruth\\n...\\nModel\\nPrediction\\nPrompt:\\nGrade Model Prediction, based\\non the Ground Truth ...\\nGrading Agent\\n...\\n7/10\\n8/10\\n6/10\\n...\\nSAQ Scores\\nTested LLMs\\nFig. 5. SAQ evaluation process:A sufficiently powerful LLM is used as the agent to grade the model\\nprediction.\\n[5] as the grading agent, which achieves the balance between the performance (sufficient for the\\nabove two goals) and cost.\\n5 Evaluation\\nBased on SecBench, we conducted extensive benchmarking on 13 SOTA LLMs, including the GPT\\nseries and competitive open-source ones.\\n5.1 MCQ Benchmarking\\nTable 1 presents the benchmarking results for the 44,823 MCQs. The values in each cell represent the\\ncorrectness percentage for the corresponding category. Overall, the correctness of KR is significantly\\nhigher than that of LR, demonstrating the rationale behind our design (i.e., Logical Reasoning\\nis more challenging than Knowledge Retention). The performance of smaller LLMs (with fewer\\nthan 10 billion parameters) is predictably lower than that of larger LLMs (with more than 30\\nbillion parameters) Notably, the Tencent Hunyuan-Turbo model [7] outperforms all existing models,\\nincluding the state-of-the-art GPT-4o and GPT-4o-mini, achieving the highest correctness of 94.28%.\\nIts correctness in Logical Reasoning (93.06%) is also significantly higher than that of other models,\\ndemonstrating Hunyuan-Turbo’s strong capability in solving complex questions in cybersecurity.\\n5.2 SAQ Benchmarking\\nTable 2 presents the benchmarking results for the 3,087 short-answer questions (SAQs). The values\\nin each cell represent the average score, graded by the grading agent, on a percentage scale for\\nthe corresponding category. Compared to MCQs, a larger gap is observed between different LLMs,\\nindicating that solving SAQs is more challenging than MCQs. This is because the tested LLMs are\\nrequired to generate their own answers rather than simply choosing from given options. Notably,\\nfor SAQs, the Tencent Hunyuan-Turbo model [7] also outperforms most existing models, achieving\\na score of 82.13. It ranks second only to the state-of-the-art GPT-4o (85.17) and is competitive with\\nthe GPT-4o-mini (82.49).\\n6 Discussion\\nRationale for Using LLMs in the Process.We utilized GPT-4o [6] for labeling data during the\\nconstruction phase of SecBench, and GPT-4o-mini [5] for grading SAQs in the benchmarking phase.\\nTo ensure that these two LLMs are capable of performing the tasks, we explicitly checked their'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 8, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='8 Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, and Xiapu Luo\\nTable 1. MCQ Benchmarking:The average correctness (values are percentage numbers) for all 44,823\\nMCQs. Average: Average correctness of all MCQs.Level: KR - Knowledge Retention; LR - Logical Reasoning.\\nLanguage: CH - Chinese; EN - English. Domain: Sub-domains from D1 to D9 in Fig.1.\\nLevel Language Domain\\nAverageKR LR CH EN D1 D2 D3 D4 D5 D6 D7 D8 D9\\nGPT-4o[6] 90.99 91.82 82.75 92.87 83.23 90.32 90.32 88.71 90.51 94.13 89.61 84.43 93.54 90.00\\nGPT-4o-mini[5] 88.79 89.86 78.27 91.37 78.17 88.07 88.30 84.71 88.86 92.84 86.91 75.78 92.90 87.33\\nGPT-3.5-Turbo[3]86.36 87.26 77.43 89.25 74.44 84.71 84.64 82.40 88.34 91.04 81.47 73.84 91.08 84.39\\nHunyuan-Turbo[7]94.28 94.41 93.06 95.58 88.95 94.28 93.85 93.81 93.38 95.77 94.44 93.73 95.51 91.06\\nGLM-4-9B[1] 84.57 85.14 78.95 88.26 69.38 83.26 81.41 80.18 87.11 89.01 80.43 71.35 89.82 83.23\\nLlama-3-8B[8] 77.71 78.43 70.58 80.70 65.43 77.26 74.34 73.07 77.48 82.85 74.51 62.92 84.14 76.74\\nDeepSeek-V2-Lite[2]79.07 80.07 69.22 83.40 61.26 78.21 74.86 73.73 82.48 84.56 71.85 65.51 85.23 76.60\\nQwen2-7B[11] 87.74 88.29 82.29 90.77 75.29 86.94 85.79 85.20 89.38 90.69 83.41 82.49 91.86 83.74\\nYi-1.5-9B[14] 86.44 87.03 80.57 89.04 75.74 85.58 85.61 83.90 87.19 89.74 83.93 80.76 89.63 82.22\\nLlama-3-70B[8] 88.86 89.46 82.97 90.95 80.28 87.27 87.95 85.95 88.54 92.81 87.96 81.95 92.44 87.24\\nQwen2-72B[11] 92.41 92.71 89.50 94.50 83.83 91.90 91.55 91.04 93.01 94.56 90.78 90.05 94.26 89.13\\nYi-1.5-34B[14] 89.59 90.04 85.19 91.48 81.82 89.14 88.71 88.47 90.00 92.20 88.44 87.14 91.38 84.15\\nMixtral-8x7B[9] 86.08 86.78 79.19 88.58 75.76 85.05 84.70 81.52 87.30 91.04 83.13 75.35 89.75 84.39\\nTable 2. SAQ Benchmarking:The average scores graded by the grading agent (converted to a percentage\\nscale). Average: Average correctness of all 3087 SAQs. Level: KR - Knowledge Retention; LR - Logical\\nReasoning. Language: CH - Chinese; EN - English. Domain: Sub-domains from D1 to D9 in Fig.1.\\nLevel Language Domain\\nAverageKR LR CH EN D1 D2 D3 D4 D5 D6 D7 D8 D9\\nGPT-4o[6] 85.17 84.37 85.63 84.95 93.25 85.18 86.91 83.19 84.04 85.14 85.55 83.44 85.78 90.36\\nGPT-4o-mini[5] 82.49 81.17 83.25 82.26 91.12 82.55 84.18 79.52 81.44 82.70 84.31 81.56 84.34 87.12\\nGPT-3.5-Turbo[3]74.78 75.54 74.34 74.49 85.50 74.32 76.15 72.83 72.95 75.09 76.72 77.50 74.22 80.45\\nHunyuan-Turbo[7]82.13 79.64 83.56 81.94 89.00 82.89 84.52 79.77 81.78 81.45 84.38 81.25 83.35 83.96\\nGLM-4-9B[1] 66.26 65.06 66.95 65.91 79.38 67.47 67.32 62.35 67.26 66.21 67.66 66.25 67.17 73.15\\nLlama-3-8B[8] 62.39 60.48 63.50 62.11 73.12 62.77 66.40 58.57 64.11 61.94 61.32 61.56 62.89 69.19\\nDeepSeek-V2-Lite[2]44.84 47.09 43.55 44.55 55.75 43.78 44.44 45.80 34.73 44.77 47.15 49.38 49.02 50.00\\nQwen2-7B[11] 59.99 53.39 63.79 60.14 54.25 63.67 64.71 53.67 62.61 57.75 60.80 55.94 63.78 67.57\\nYi-1.5-9B[14] 65.24 64.98 65.39 65.01 73.88 65.86 67.04 62.61 63.77 64.47 66.57 66.88 66.36 74.23\\nLlama-3-70B[8] 68.12 65.93 69.47 69.48 20.62 71.20 67.35 65.81 70.87 67.64 72.67 71.61 67.31 63.14\\nQwen2-72B[11] 82.13 75.93 85.70 81.96 88.25 84.82 85.45 76.89 86.85 80.52 83.21 80.00 85.14 86.13\\nYi-1.5-34B[14] 75.03 67.82 79.18 74.75 85.38 79.25 78.27 68.05 76.71 73.71 77.37 62.50 79.25 81.80\\nMixtral-8x7B[9] 74.78 72.42 76.15 74.38 89.88 75.06 78.44 71.01 73.42 74.37 77.23 74.38 76.65 80.18\\noutput. Specifically, we randomly sampled a mini-batch from the output for manual verification\\nand validated that (1) GPT-4o can successfully label the questions into the corresponding capability\\nlevel and sub-domain, and (2) GPT-4o-mini can fairly grade the LLMs’ answers based on the ground\\ntruth.\\nLanguage Bias.SecBench exhibits a language bias towards Chinese (80.4% in MCQs and 97.4%\\nin SAQs) because the majority of the data in SecBench comes from the Cybersecurity Question\\nDesign Contest, which is held in a Chinese context. To ensure the originality and best maintain\\nthe original meaning of the questions, we currently do NOT translate the Chinese questions into\\nEnglish or vice versa. As a result, the scale of SecBench could be further doubled via a translation\\nprocess (e.g., via another powerful LLM), which we leave as future work. Additionally, note that\\nconsidering the large scale of SecBench, it still offers a sufficient amount of English questions\\n(nearly 9,000 MCQs and 100 SAQs) for benchmarking.'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 9, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity 9\\n7 Conclusion\\nWe propose SecBench, a multi-dimensional benchmarking dataset specifically designed to evaluate\\nLLMs in the cybersecurity domain. SecBench addresses the limitations of existing benchmarks by\\nincluding questions in various formats (MCQs and SAQs), at different capability levels (Knowledge\\nRetention and Logical Reasoning), in multiple languages (Chinese and English), and across various\\nsub-domains. The dataset was meticulously constructed by collecting high-quality data from open\\nsources and organizing a Cybersecurity Question Design Contest, resulting in 44,823 MCQs and\\n3,087 SAQs. To ensure the quality and consistency of the dataset, we employed GPT-4 for data\\nlabeling and GPT-4o-mini as a grading agent for the automatic evaluation of SAQs. Benchmarking\\nresults demonstrate the usability and comprehensiveness of SecBench, making it arguably the\\nlargest and most detailed benchmark dataset for LLMs in the field of cybersecurity. More information\\nabout SecBench can be found at our website [13], and the dataset can be accessed via the artifact\\nlink [12].\\nReferences\\n[1] 2024. ChatGLM: A Family of Large Language Models from GLM-130B to GLM-4 All Tools. https://arxiv .org/pdf/\\n2406.12793.\\n[2] 2024. DeepSeek-V2: A Strong, Economical, and Efficient Mixture-of-Experts Language Model. https://arxiv .org/abs/\\n2405.04434.\\n[3] 2024. GPT-3.5-Turbo. https://platform .openai.com/docs/models/gpt-3-5-turbo.\\n[4] 2024. GPT-4 API. https://platform .openai.com/docs/models/gp#gpt-4-turbo-and-gpt-4.\\n[5] 2024. GPT-4o mini: advancing cost-efficient intelligence. https://openai .com/index/gpt-4o-mini-advancing-cost-\\nefficient-intelligence/.\\n[6] 2024. GPT-4o: OpenAI’s new flagship model that can reason across audio, vision, and text in real time. https:\\n//openai.com/index/hello-gpt-4o/.\\n[7] 2024. Hunyuan-Large: An Open-Source MoE Model with 52 Billion Activated Parameters by Tencent. https://\\nllm.hunyuan.tencent.com/.\\n[8] 2024. Introducing Meta Llama 3: The most capable openly available LLM to date. https://ai .meta.com/blog/meta-\\nllama-3/.\\n[9] 2024. Mixtral of Experts. https://arxiv .org/pdf/2401.04088.\\n[10] 2024. OpenCompass: An Open-sourced Platform for Evaluation LLMs. https://github .com/open-compass/\\nopencompass.\\n[11] 2024. Qwen2 Technical Report. https://arxiv .org/abs/2407.10671.\\n[12] 2024. SecBench: Artifact. https://zenodo .org/records/14575303.\\n[13] 2024. SecBench: Comprehensively Benchmarking LLMs in Cybersecurity. https://secbench .org/.\\n[14] 2024. Yi: Open Foundation Models by 01.AI. https://github .com/01-ai/Yi-1 .5.\\n[15] Dipkamal Bhusal, Md Tanvirul Alam, Le Nguyen, Ashim Mahara, Zachary Lightcap, Rodney Frazier, Romy Fieblinger,\\nGrace Long Torales, and Nidhi Rastogi. 2024. SECURE: Benchmarking Generative Large Language Models for\\nCybersecurity Advisory. arXiv preprint arXiv:2405.20441 (2024).\\n[16] C-Eval. 2024. C-Eval: A Multi-Level Multi-Discipline Chinese Evaluation Suite for Foundation Models. https:\\n//cevalbenchmark.com/\\n[17] HumanEval. 2024. HumanEval: Hand-Written Evaluation Set. https://github .com/openai/human-eval\\n[18] Zefang Liu. 2023. Secqa: A concise question-answering dataset for evaluating large language models in computer\\nsecurity. arXiv preprint arXiv:2312.15838 (2023).\\n[19] Zefang Liu, Jialei Shi, and John F Buford. 2024. Cyberbench: A multi-task benchmark for evaluating large language\\nmodels in cybersecurity.\\n[20] MMLU. 2024. Measuring Massive Multitask Language Understanding (MMLU). https://github .com/hendrycks/test\\n[21] Norbert Tihanyi, Mohamed Amine Ferrag, Ridhi Jain, Tamas Bisztray, and Merouane Debbah. 2024. CyberMetric: A\\nBenchmark Dataset based on Retrieval-Augmented Generation for Evaluating LLMs in Cybersecurity Knowledge. In\\n2024 IEEE International Conference on Cyber Security and Resilience (CSR) . IEEE, 296–302.'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 10, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='10 Pengfei Jing, Mengyun Tang, Xiaorong Shi, Xing Zheng, Sen Nie, Shi Wu, Yong Yang, and Xiapu Luo\\nA Detailed Prompts\\nLLM-based labeling.Following is the prompt text that is implemented on GPT-4 for labeling\\nSecBench data. In the prompt, we explicitly detailed the requirement and offered few-shot example\\nto ensure the performance.\\n# Task Description\\nI will upload a question related to information security, and now I need you to help me annotate these questions. I\\nneed you to annotate these questions from two dimensions: 1. Assessing ability: whether the question assesses basic\\nKnowledge Retention or more challenging Logical Reasoning ability. 2. Assessing domain: which specific subfield the\\nquestion belongs to. Next, I will elaborate on these two requirements:\\n1.Assessing ability. First, you will classify each question into one of the following two categories: (a). Knowledge\\nRetention question: This type of question tests whether the test taker has the relevant background knowledge through\\nstraightforward descriptions. The answers to these questions can be obtained directly by querying the knowledge base\\nand do not involve reasoning processes. (b). Logical Reasoning question: This type of question presents the test taker\\nwith a specific scenario and requires the test taker to reason or calculate within that scenario to arrive at the correct\\nanswer. Compared to Knowledge Retention questions, these questions are more challenging.\\n2.Assessing domain. Next, you will annotate the specific domain that each question assesses into one of the following\\n10 categories: (1). Identity and Access Control, (2). Cloud Security, (3). Endpoint and Host Security, (4). Security\\nStandards and Regulations, (5). Data Security, (6). Security Management, (7). Network and Infrastructure Security, (8).\\nFundamental Software and Hardware Technology, (9). Application Security, (10). Others. Note that if you believe a\\nquestion cannot be classified into any of the categories (1) (9), then classify it as (10). Others.\\nFinally, you will provide the reason and basis for your classification of the question.\\n—\\n# Input Introduction\\nThe questions I upload consist of the following format:\\n{\"question\":\"Which of the following is directly related to database security?\", \"answers\":[\"Granularity of access con-\\ntrol\", \"Size of the database\", \"Number of attributes in the relation table\", \"Number of tuples in the relation table\"], \"label\":\"A\"}\\nEach line of the file includes 3 elements: question is the main body of the question, answers are the four provided\\noptions, and label is the correct answer.\\n—\\n# Output Requirements\\nFor each question I upload, you will annotate it according to my requirements and add the annotation results directly\\nto the original data. The annotation results should be in Chinese. You will insert the annotation results after each piece\\nof data, including:\\n- \"assessed ability\": whether it is Knowledge Retention or Logical Reasoning.\\n- \"assessed domain\": which domain the knowledge being assessed belongs to.\\n- \"reason for labeling\": the reason for your annotation, including the reason for the ability annotation and the reason\\nfor the domain annotation, all need to be explained. This explanation must be detailed and explain why you believe the\\nquestion assesses knowledge from a specific domain, not just give a meaningless reason.\\nUsing the example question from the \"Data Introduction\" section, the annotated result should be as follows:\\n{ \"question\": \"Which of the following is directly related to database security?\", \"answers\": [\"Granularity of access\\ncontrol\", \"Size of the database\", \"Number of attributes in the relation table\", \"Number of tuples in the relation table\"],\\n\"label\": \"A\", \"assessed ability\": \"Knowledge Retention\", \"assessed domain\": \"Data Security\", \"reason for labeling\": \"This\\nquestion directly tests specific basic knowledge related to database security and does not involve logical reasoning,\\nso it is labeled as knowledge memory; it can be directly seen from the question stem that this question tests specific\\nknowledge of database security and should be classified under ’Data Security’. \" }\\n—'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.20787v1.SecBench__A_Comprehensive_Multi_Dimensional_Benchmarking_Dataset_for_LLMs_in_Cybersecurity.pdf', 'page_number': 11, 'total_pages': 11, 'entry_id': 'http://arxiv.org/abs/2412.20787v1', 'title': 'SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity', 'authors': ['Pengfei Jing', 'Mengyun Tang', 'Xiaorong Shi', 'Xing Zheng', 'Sen Nie', 'Shi Wu', 'Yong Yang', 'Xiapu Luo'], 'published': '2024-12-30', 'updated': '2024-12-30', 'primary_category': 'cs.CR', 'categories': ['cs.CR', 'cs.AI'], 'pdf_url': 'http://arxiv.org/pdf/2412.20787v1'}, text='SecBench: A Comprehensive Multi-Dimensional Benchmarking Dataset for LLMs in Cybersecurity 11\\n# Judgment Criteria\\nFor the first annotation task (i.e., 1. Assessing ability), you will follow the following criteria:\\n(1). Questions involving numerical calculations (e.g., encryption and decryption algorithms) must be Logical Reasoning\\nquestions.\\n(2). Questions involving specific code or Linux commands must be Logical Reasoning questions.\\n(3). If the question stem provides a hypothetical subject (e.g., specific names, a company, an organization, a security\\nanalyst) and describes this hypothetical subject in detail, and the question is designed based on this, then the question\\nmust be a Logical Reasoning question.\\n(4). Questions with relatively long stems are more likely to be Logical Reasoning questions (because the stem contains\\nmore information, often requiring the test taker to understand and reason). Conversely, questions with shorter stems\\nare more likely to be Knowledge Retention questions. Note: This criterion is not absolute and can only serve as an\\nauxiliary judgment criterion.\\n—\\n# Few-shot Examples\\n{ \"question\": \"Interface testing could involve which of the following?\", \"answers\": [\"The application programming\\ninterface (API)\", \"The graphical user interface (GUI)\", \"Both of the above\", \"None of the above\"], \"label\": \"C\", \"assessed\\nability\": \"Knowledge Retention\", \"assessed domain\": \"Application Security\", \"reason for labeling\": \"This question directly\\ntests whether the candidate understands the specific process of interface testing and does not involve complex logical\\nreasoning, so it is labeled as knowledge memory; interface testing is often related to specific applications, so it is\\nclassified under ’Application Security’. \" }\\n{ \"question\": \"Two-key triple DES encryption: C=CK1[DK2[EK1[P]]], K1≠K2, where the effective key is ()\", \"answers\":\\n[\"56\", \"128\", \"168\", \"112\"], \"label\": \"D\", \"assessed ability\": \"Logical Reasoning\", \"assessed domain\": \"Data Security\", \"reason\\nfor labeling\": \"This question requires the candidate to understand DES encryption and calculate the correct answer\\nbased on the question stem, involving a logical reasoning process, so it is labeled as logical reasoning; the question\\ntests encryption algorithms and is directly related to data security, so it is classified under ’Data Security’. \" }\\n...\\n—\\nNow please annotate the following question:\\n{Input Question}\\nSAQ Grading.Following is the prompt that the grading agent (implemented on GPT-4o-mini in\\nour work) used to grade the LLM’s output for benchmarking SAQs.\\nPlease help me grade a student’s answers in the network information security exam. I will provide you with a dataset\\nthat contains three parts: 1. The question stem and specific question, 2. The standard answer (i.e., the full score answer),\\n3. The student’s answer (to be graded). Specifically, you will perform the following steps:\\n1. For each question, read the question stem and understand the content of the question.\\n2. For each question, read the student’s answer and compare it with the standard answer.\\n3. For each question, based on the differences between the student’s answer and the standard answer, grade the\\nstudent’s answer. The question is scored on a 10-point scale, with a full score of 10 points.\\nRecord and return the student’s score for each question in the form of a JSON file.\\n—\\nYour output should only contain a JSON file in the following format, where each data entry only includes the student’s\\nscore, with the key being \"score\" and the value being an integer between 0 and 10, inclusive, for example:\\n[{\"model_score\": 6}]\\n—\\nBelow are the questions you need to process, consisting of three parts: 1. The question stem and specific question, 2.\\nThe standard answer (i.e., the full score answer), 3. The student’s answer (to be graded). Please grade based on the data\\nbelow and return the JSON file in the format mentioned above:\\n1. The question stem: {Question Stem from SecBench}\\n2. The standard answer (i.e., the full score answer): {Ground Truth from SecBench}\\n3. The student’s answer (to be graded): {LLM’s output to be graded}'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf', 'page_number': 1, 'total_pages': 21, 'entry_id': 'http://arxiv.org/abs/2412.13420v1', 'title': 'BotSim: LLM-Powered Malicious Social Botnet Simulation', 'authors': ['Boyu Qiao', 'Kun Li', 'Wei Zhou', 'Shilong Li', 'Qianqian Lu', 'Songlin Hu'], 'published': '2024-12-18', 'updated': '2024-12-18', 'primary_category': 'cs.SI', 'categories': ['cs.SI'], 'pdf_url': 'http://arxiv.org/pdf/2412.13420v1'}, text='BotSim: LLM-Powered Malicious Social Botnet Simulation\\nBoyu Qiao1,2, Kun Li1*, Wei Zhou1, Shilong Li1,2, Qianqian Lu1, Songlin Hu1,2\\n1Institute of Information Engineering, Chinese Academy of Sciences\\n2School of Cyber Security, University of Chinese Academy of Sciences\\n{qiaoboyu, likun2, zhouwei, lishilong, luqianqian, husonglin}@iie.ac.cn\\nAbstract\\nSocial media platforms like X(Twitter) and Reddit are vital\\nto global communication. However, advancements in Large\\nLanguage Model (LLM) technology give rise to social media\\nbots with unprecedented intelligence. These bots adeptly sim-\\nulate human profiles, conversations, and interactions, dissem-\\ninating large amounts of false information and posing signif-\\nicant challenges to platform regulation. To better understand\\nand counter these threats, we innovatively design BotSim, a\\nmalicious social botnet simulation powered by LLM. Bot-\\nSim mimics the information dissemination patterns of real-\\nworld social networks, creating a virtual environment com-\\nposed of intelligent agent bots and real human users. In the\\ntemporal simulation constructed by BotSim, these advanced\\nagent bots autonomously engage in social interactions such as\\nposting and commenting, effectively modeling scenarios of\\ninformation flow and user interaction. Building on the Bot-\\nSim framework, we construct a highly human-like, LLM-\\ndriven bot dataset called BotSim-24 and benchmark multi-\\nple bot detection strategies against it. The experimental re-\\nsults indicate that detection methods effective on traditional\\nbot datasets perform worse on BotSim-24, highlighting the\\nurgent need for new detection strategies to address the cyber-\\nsecurity threats posed by these advanced bots.\\nCode — https://github.com/QQQQQQBY/BotSim\\nIntroduction\\nIn the modern digital era, online social networks (OSNs)\\nsuch as X (formerly Twitter), and Reddit have become es-\\nsential mediums for shaping human interaction due to their\\nextensive connectivity and real-time information exchange.\\nHowever, the prevalence of bots on these platforms poses\\na significant threat to OSN security (Cresci 2020; Ferrara\\n2023). For example, social bots have played notable roles\\nin major events like presidential elections (Guglielmi 2020;\\nPacheco 2024) and global pandemics (Gallotti et al. 2020;\\nHimelein-Wachowiak et al. 2021), where they disseminate\\nmisinformation and sway public opinion. Previous instances\\nof social bots primarily stem from rule-based programs,\\nhowever, recent advancements have integrated large lan-\\nguage models (LLMs) that endow bots with more sophis-\\n*Corresponding Author.\\nCopyright © 2025, Association for the Advancement of Artificial\\nIntelligence (www.aaai.org). All rights reserved.\\nticated, human-like capabilities (Yang and Menczer 2024).\\nThis development has further intensified the problem of in-\\nformation pollution on OSNs (Sun et al. 2024). Therefore,\\nupgrading current detection systems and understanding the\\ncharacteristics of LLM-driven bots has become a critical pri-\\nority.\\nPrevious research methods have predominantly been de-\\nveloped using traditional bot datasets. For instance, Yang\\net al. (2020) proposed a method that exploits differences\\nin user profiles, while Cresci et al. (2016) suggested iden-\\ntifying the longest common subsequence of user actions.\\nWith advancements in deep learning, new methods have\\nemerged focusing on text semantic content and user inter-\\naction networks. Wei et al. (2019) introduced the use of re-\\ncurrent neural networks (RNNs) to encode posts and detect\\nbots based on their semantic content. More recent meth-\\nods, such as RGT (Feng et al. 2022), and BECE (Qiao\\net al. 2024) have employed graph neural networks (GNNs)\\nand graph-enhanced strategies to improve detection perfor-\\nmance. However, LLM-powered bots exhibit greater logical\\ncoherence and human-like qualities in profiles, text content,\\nand interaction strategies, posing significant challenges to\\nthese existing detection methods (Feng et al. 2024; Ferrara\\n2023). Therefore, collecting datasets of LLM-driven bots\\nis essential for developing new detection techniques (Yang\\nand Menczer 2024). Traditional dataset collection methods,\\nhowever, encounter the following two major challenges:\\n(1) Intelligent Challenges and Decline in Labeling Qual-\\nity: The intelligence of LLM-driven bots has significantly\\nadvanced, making manual annotation tasks much more chal-\\nlenging and leading to a notable decline in annotation qual-\\nity (Zhang et al. 2024). For instance, crowdsourcing tests\\nconducted by Cresci et al. (2017) revealed that manual an-\\nnotators had an accuracy rate of less than 24% when labeling\\nsocial spam bots. Consequently, manual annotation has be-\\ncome unreliable, impairing the ability of detection models to\\ndifferentiate between bots and genuine users.\\n(2) Ethical Constraints: For ethical reasons, large-scale de-\\nployment of social bots disguised as humans in real social\\nnetworks to obtain genuine annotations for research is sub-\\nject to strict restrictions. This situation makes research more\\ncomplex and challenging.\\nTo address these challenges, we design a scalable ma-\\nlicious social botnet simulation framework called BotSim,\\narXiv:2412.13420v1  [cs.SI]  18 Dec 2024'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf', 'page_number': 2, 'total_pages': 21, 'entry_id': 'http://arxiv.org/abs/2412.13420v1', 'title': 'BotSim: LLM-Powered Malicious Social Botnet Simulation', 'authors': ['Boyu Qiao', 'Kun Li', 'Wei Zhou', 'Shilong Li', 'Qianqian Lu', 'Songlin Hu'], 'published': '2024-12-18', 'updated': '2024-12-18', 'primary_category': 'cs.SI', 'categories': ['cs.SI'], 'pdf_url': 'http://arxiv.org/pdf/2412.13420v1'}, text='upon which we construct an accurately labeled, LLM-driven\\nbot dataset named BotSim-24. This dataset includes both\\nreal human accounts and LLM-driven agent bot accounts.\\nTo enhance the dataset’s complexity, we implement a series\\nof disguise techniques based on detection methods proposed\\nin previous research focusing on bot profiles (Yang et al.\\n2020), textual content (Qiao et al. 2023), and interaction\\nbehavior patterns (Li et al. 2023). By leveraging LLMs to\\nanalyze and simulate characteristics of real users, we con-\\nstruct a comprehensively disguised and highly human-like\\nLLM-driven bot dataset to expose and challenge the limita-\\ntions and weaknesses of existing detection methods. We then\\nbenchmark multiple bot detection strategies on the BotSim-\\n24 dataset. The experimental results validate the effective-\\nness of the dataset and underscore the significant threat that\\nadvanced bots pose to network security.\\nOur contributions can be summarized as follows:\\n• BotSim Framework: We are the first to propose a\\nscalable LLM-driven malicious social botnet simula-\\ntion framework, BotSim. This environment enables re-\\nsearchers to continuously track the latest bot evolution\\nstrategies and generate up-to-date datasets, thereby ad-\\nvancing the development of new detection methods.\\n• LLM-Driven Bot Dataset: Leveraging the BotSim sim-\\nulation framework, we meticulously construct a bot de-\\ntection dataset based on interaction scenarios from Red-\\ndit. This dataset incorporates real Reddit users and LLM-\\ndriven bot accounts, providing a comprehensive range of\\ninteraction data that enhances existing resources for so-\\ncial bot detection research.\\n• Experimental Evaluation: We conduct extensive exper-\\niments on the BotSim-24 dataset to evaluate the perfor-\\nmance of various social bot detection models. The results\\nshow that detection methods effective on traditional bot\\ndatasets perform poorly on BotSim-24, highlighting the\\nurgent need for new detection strategies to address the\\ncybersecurity threats posed by these advanced bots.\\nBotSim: Botnet Simulation Framework\\nThe overall framework of BotSim is shown in Figure 1, and\\nit aims to model the activity characteristics and behavior pat-\\nterns of LLM-driven malicious social bots in OSNs. BotSim\\nconsists of four components: the social environment, envi-\\nronmental perception, action list, and agent decision center.\\nPreliminaries\\nIn this paper, we aim to use a botnet simulation framework\\nto model the activity characteristics and behavior patterns of\\nLLM-driven malicious bots on OSNs. The BotSim frame-\\nwork includes two types of users: human accounts from real\\nsocial ecosystems, denoted as UH = {Uh1 , Uh2 , ..., Uhn }\\nand LLM-driven agent bot accounts, denoted as UB =\\n{Ub1 , Ub2 , ..., Ubm }, where n and m represent the number\\nof humans and bots, respectively. To simulate the continu-\\nous passage of time and the dynamic changes in interaction\\ntiming in real OSNs, we set up a timeline mechanism T =\\n{t1, t2, ..., tn}. In the timeline process, the set of interactions\\nbetween users is represented as D = {UB, UH, E, T} with\\nE = {e1, e2, ..., en} denoting the set of interaction relation-\\nships among users.\\nSocial Environment\\nThe social environment of BotSim is built from real social\\nmedia ecosystem data and consists of account collection,\\nmessage feeding, timeline setup, and interaction mode.\\nAccount Collection The account collection includes real\\nhuman accounts UH and virtual Agent bot accountsUB. Hu-\\nman accounts are sourced from data collected in real social\\nenvironments, while the configuration and behavior of agent\\nbot accounts are constructed by LLM-driven agents.\\nMessage Feeding Message feeding utilizes a dual-filtering\\nmechanism based on timelines and recommendation func-\\ntions. Initially, the message flow is filtered through the time-\\nline, and then it is optimally ranked by the recommendation\\nfunction to produce the final message stream.\\nTimeline Setup The timeline setup T = {t1, t2, ..., tn}\\nensures the environment operates according to a predefined\\ntimeline logic. Additionally, each agent bot has its dedicated\\ntimeline, which is determined by the bot’s activities and in-\\nteractions with other accounts to meet the need for rapid\\nsimulation of long-time-span interactions.\\nInteraction Mode The interaction patterns E =\\n{e1, e2, ..., en} must adhere to the interaction settings de-\\nfined by the specific social media platform. Interactions be-\\ntween accounts are accompanied by message flow outputs,\\nsuch as likes and comments on current messages.\\nEnvironment Perception\\nThe environment perception mechanism is important in the\\noperation of BotSim, which helps the agent to capture the\\ndynamic changes of the social environment and accurately\\ntransfer the perceived multi-dimensional information to the\\nagent decision center so that the agent can make adaptive\\ndecisions based on the environmental information.\\nIn BotSim, account profiles, message stream updates, and\\ncomplex interaction data collectively form the core elements\\nof the social environment. To enhance the agents’ under-\\nstanding and responsiveness to these complex environments,\\nwe have designed clear and structured prompts to assist\\nthe LLM in comprehending environmental information. De-\\ntailed prompts can be found in Appendix B.1.\\nAction List\\nThe action list integrates commonly used information dis-\\nsemination interactions on social media, including the fol-\\nlowing actions: (1) Create User: Create a new user profile.\\n(2) Post: Generate and publish original content based on\\nbackground knowledge and preferences. (3) Comment: Re-\\nply to selected posts or comments. (4) Repost: Share posts\\nto achieve targeted information dissemination. (5) Like:\\nLike posts to enhance positive feedback during interactions.\\n(6) Browse: Continue browsing the message stream based\\non the internal timeline if no preferred content is found. (7)\\nEnd: Complete the mission and terminate the action.'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf', 'page_number': 3, 'total_pages': 21, 'entry_id': 'http://arxiv.org/abs/2412.13420v1', 'title': 'BotSim: LLM-Powered Malicious Social Botnet Simulation', 'authors': ['Boyu Qiao', 'Kun Li', 'Wei Zhou', 'Shilong Li', 'Qianqian Lu', 'Songlin Hu'], 'published': '2024-12-18', 'updated': '2024-12-18', 'primary_category': 'cs.SI', 'categories': ['cs.SI'], 'pdf_url': 'http://arxiv.org/pdf/2412.13420v1'}, text='Social Media Platform \\nReal Datasets\\nAccounts Messages\\nInteraction\\nSocial Environment\\nEnvironment Perception\\nSocial\\nNetwork\\nPosts\\nComments\\nUser \\nProfiles\\ndoomed\\n@doomed\\nOrlando, FL\\nNovember 2008\\nGreat article  for ....\\nAnna\\n9 Minutes ago\\nZoe\\na few seconds ago\\nWhen I first ...\\nCreate Post\\nLike Comment\\nRepost ...\\nAction List\\nRole\\nMemory\\nGoal\\nPerception\\nActions\\nKnowledge Relevant historical \\ncontent\\nMemory\\nHistorical Posts\\nHistorical Comments\\nGoal Tasks\\nGoal\\nAction 1\\nAction n\\nbreak \\ndown\\nAgent\\nAgent Decision CenterPrompt\\n  Large Language \\n  Model (LLM)\\nDecision Making\\nReasoning\\n/Responsing\\nTimeline\\n...\\nUser Info\\n Relationship\\nFigure 1: The overall framework of BotSim.\\nBotSim provides a list of commonly used actions for in-\\nformation dissemination across various OSNs. Future re-\\nsearch can select the appropriate actions based on specific\\nneeds and add new actions as required. Detailed description\\nof the action list in Appendix B.2.\\nAgent Decision Center\\nThe Agent Decision Center, as the core component of Bot-\\nSim, integrates multidimensional information including goal\\ntasks, role settings, background knowledge, environmental\\nperception, action lists, and memory data. Its primary func-\\ntion is to accurately plan and execute action decisions, driv-\\ning the comprehensive operation of BotSim.\\nGoal Tasks Goal tasks G define the specific needs for\\ninformation dissemination and guide the agent’s actions.\\nThe operators set these goals, and then the LLM decom-\\nposes the goal tasks into manageable and planned actions\\nPA = {pa1, pa2, ..., pak} to ensure the goals are achieved.\\nPrompts for goal tasks are detailed in Appendix B.3.\\nRole Setting Role settings are crucial for the agent’s\\ndecision-making process and include multidimensional at-\\ntributes such as age, name, gender, preferences, education\\nlevel, description, and geographic location. These attributes\\nare applied to the profiles of created user accounts to help the\\nagent establish a persona, enhancing both emotional expres-\\nsion and decision-making accuracy. More detailed informa-\\ntion on role setup is provided in Appendix B.2.\\nBackground Knowledge Given that LLMs may struggle\\nto capture new social dynamics and knowledge, providing\\nbackground knowledge KL can help LLMs generate rele-\\nvant and novel content that aligns with goal tasks.\\nMemory Mechanism The memory mechanism filters rele-\\nvant posts and comments related to the current task from the\\nagent’s historical records. This mechanism assists the agent\\nin responding appropriately. An example of memory infor-\\nmation is presented in Appendix B.4.\\nBotSim Execution Process\\nThe overall execution process of the agent bots in BotSim in-\\nvolves the following steps: (1) Specify the Platform: Iden-\\ntify the social media platform to be simulated and gather the\\nrelevant data, including user profiles, messages, timestamps,\\nand interaction data. (2) Define Goal Tasks: Clearly out-\\nline the goal tasks and compile the necessary background\\nknowledge. (3) Break Down Tasks: Decompose the goal\\ntasks into a series of executable actions, as detailed in Ap-\\npendix B.3. (4) Formulate Environment Prompts: Per-\\nceive changes in the simulated social environment and cre-\\nate appropriate prompts, as detailed in Appendix B.1. (5)\\nRetrieve Memory Data: Access historical posts and com-\\nments relevant to the goal task. (6) Construct and Execute\\nPrompts: Build prompts using environmental perception in-\\nformation, memory data, planned action sequences, role set-\\ntings, and background knowledge. Use these prompts to in-\\nstruct the LLM, which will return the required action param-\\neters. (7) Update and Monitor: Refresh the social environ-\\nment and track the progress of the action sequence. If not\\ncompleted, return to step (4). If completed, proceed to step\\n(8). (8) End: Conclude the execution.\\nA complete prompt example is provided in Appendix B.4,\\nand the algorithm for this execution process is further ex-\\nplained in Appendix B.5.\\nBotSim-24: LLM-driven Bot Detection Dataset\\nIn this section, we present BotSim-24, a bot detection dataset\\npowered by LLM. Building on the BotSim framework, we\\nsimulate information dissemination and user interactions\\nacross six SubReddits on Reddit. This process results in the'),\n",
       " Document(metadata={'file_path': 'arxiv_papers/2412.13420v1.BotSim__LLM_Powered_Malicious_Social_Botnet_Simulation.pdf', 'page_number': 4, 'total_pages': 21, 'entry_id': 'http://arxiv.org/abs/2412.13420v1', 'title': 'BotSim: LLM-Powered Malicious Social Botnet Simulation', 'authors': ['Boyu Qiao', 'Kun Li', 'Wei Zhou', 'Shilong Li', 'Qianqian Lu', 'Songlin Hu'], 'published': '2024-12-18', 'updated': '2024-12-18', 'primary_category': 'cs.SI', 'categories': ['cs.SI'], 'pdf_url': 'http://arxiv.org/pdf/2412.13420v1'}, text='creation of the BotSim-24 dataset, which includes 1,907 hu-\\nman accounts and 1,000 LLM-driven agent bot accounts.\\nPre-Prepared Data\\nWe first introduce the real OSN data information that must\\nbe pre-prepared for the BotSim simulation.\\nReddit Social Environment Data Collection We choose\\nsix popular news-related SubReddits on Reddit to construct\\nthe social environment data for BotSim: “worldnews”, “pol-\\nitics”, “news”, “InternationalNews”, “UpliftingNews” and\\n“GlobalTalk”. We collect posts, first- and second-level com-\\nments, timestamps, and user profiles from these six SubRed-\\ndits between June 20, 2023, and June 19, 2024. We filter and\\nannotate the collected accounts, resulting in 1,907 human\\nReddit accounts. More detailed data filtering and statistical\\ninformation are presented in Appendix C.1.\\nGoal Tasks Our goal task is to create agent bots designed\\nto spread disinformation within six news-oriented SubRed-\\ndits. We focus on three highly debated international news\\nevents from 2023 to 2024: the “Russia-Ukraine war,” the\\n“Israeli-Palestinian conflict,” and “U.S. politics.” Our objec-\\ntive is to disseminate disinformation related to these topics\\nwhile concealing our activities by posting and engaging in\\ndiscussions about a broad spectrum of international news on\\nthe SubReddits.\\nBackground Knowledge Collection To build the knowl-\\nedge base for the three major news events and vari-\\nous international news used for our goal tasks, we col-\\nlect real news from four authoritative international news\\nsources —“BBC”, “NBC News”, “NYTimes”, and “Peo-\\nple’s Daily”, as well as fact-checking sites “Truthorfiction”\\nand “Snopes”. The data spans from June 2023 to June 2024.\\nThis knowledge base helps the LLM generate content that is\\nmost relevant to the goal tasks. More detailed statistics are\\nin Appendix C.2.\\nUser Role Role settings in BotSim are used to construct\\nthe profiles of agent bots. Usernames and descriptions are\\ngenerated by LLM simulation cases, while age, gender, ed-\\nucation level, and geographic location are randomly as-\\nsigned based on weighted statistics from Reddit1. Addition-\\nally, since the goal tasks involve international news, political\\nideology settings are included in the role settings 2. This in-\\nformation is intended to assist the agent Bots in interactions,\\nbut the BotSim-24 dataset only provides profile information\\nrelevant to Reddit.\\nBot Data Construction\\nPrevious detection methods have primarily focused on iden-\\ntifying bot accounts that lack sufficient anthropomorphic\\nfeatures in areas such as profile metadata (Value or Boolean\\ninformation) (Cresci et al. 2016; Moghaddam and Ab-\\nbaspour 2022; Beskow and Carley 2018), textual content\\n(Qiao et al. 2023; Liu et al. 2023), and interaction patterns\\n(Feng et al. 2021b; Peng et al. 2022). Our goal is to create\\nhighly human-like bot accounts, driven by LLMs and based\\n1https://explodingtopics.com/blog/reddit-users\\n2https://news.gallup.com/poll/388988/political-ideology-\\nsteady-conservatives-moderates-tie.aspx\\nSubReddit Posts Users 1-Coms 2-Coms\\nworldnews 14,626 1,405 15,740 859\\npolitics 2,4074 1,744 39,704 3,155\\nnews 8,465 1,471 11,685 441\\nInternationalNews 3,906 554 5,477 311\\nUpliftingNews 1,219 266 1,148 35\\nGlobalTalk 342 342 472 16\\nTotal 52,632 2,907 74,226 4,817\\nTable 1: Distribution of users, posts, and comments among\\nsix SubReddits. ‘1-Coms’ means first-level comments, ‘2-\\nComs’ means second-level comments. The total number of\\nusers is not the sum of users participating in different Sub-\\nReddits, but the number of accounts participating in the so-\\ncial environment.\\non the BotSim framework, to challenge these detection al-\\ngorithms. To achieve this, the bots must effectively disguise\\nthemselves in these key areas to evade detection.\\nThe disguise strategies we implement for bot accounts are\\nas follows: (1) Metadata Disguise: We statistically analyze\\nsix types of value-type metadata from real Reddit users, in-\\ncluding the number of posts, the number of first-level com-\\nments, the number of second-level comments, the ratio of\\nposts to comments, posting frequency, and the number of\\nactive SubReddits. We then use LLM to integrate this sta-\\ntistical information to generate human-like metadata for bot\\naccounts, effectively achieving metadata disguise. (2) Tex-\\ntual Content Disguise: The posts and comments of bot ac-\\ncounts are generated by LLMs based on contextual knowl-\\nedge, user role information, browsing content, and other\\nrelevant factors. Unlike traditional bots, which often pro-\\nduce posts and comments with inconsistent contextual se-\\nmantics, LLM-driven bots utilize advanced text understand-\\ning and generation capabilities to create contextually co-\\nherent and logically sound content, effectively disguising\\nthe textual output. (3) Interaction Disguise: On BotSim\\nReddit, interactions between accounts include first-level and\\nsecond-level replies. The specific posts or comments that\\nbot accounts reply to are autonomously determined by the\\nLLM based on the goal task and browsed information. This\\nmethod leverages the LLM’s analytical capabilities, distin-\\nguishing it from previous rule-based settings, and thereby\\nachieving interaction disguise. We present a more detailed\\ndata statistical analysis and the process of constructing bot\\ndata in Appendix C.3 and C.4.\\nAfter setting up the data information and construction\\nstrategies required for BotSim, we selected GPT4o-mini as\\nthe LLM for generating the BotSim-24 dataset. The BotSim-\\n24 contains users’ profiles, post and comment information,\\nand relationship information. We present the statistical in-\\nformation of the constructed BotSim-24 dataset in Table 1.\\nDataset Process\\nIn this section, we describe the construction of user features\\nand relationships in the BotSim-24 dataset.')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs_read[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
